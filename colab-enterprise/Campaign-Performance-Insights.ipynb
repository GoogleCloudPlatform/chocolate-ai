{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### To Do / License\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l85J9wppHuh3"
      },
      "source": [
        "- Create a materialize view of a campaign (all fields needed and sales and such)\n",
        "  - Generate this data if we do not have it (we need segments, sales data, coupons, channels, etc)\n",
        "- Run Data Insight on the materialized view\n",
        "- Call the REST API to get the SQL generated from Data Insights\n",
        "- Run the SQL through Gemini to create English descriptions (NOT REQUIRED)\n",
        "- The demo app will call this and run the SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```\n",
        "\n",
        "Author: Adam Paternostro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX"
      },
      "outputs": [],
      "source": [
        "# To read/write to/from Kafka\n",
        "import sys\n",
        "\n",
        "# https://PLACEHOLDER.com/index.html\n",
        "# !{sys.executable} -m pip install PLACEHOLDER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhzjo83V8KFS"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyL-Rg4Dr_f"
      },
      "source": [
        "### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYsEVSXp6IP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Audio\n",
        "from functools import reduce\n",
        "import IPython.display\n",
        "import google.auth\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import base64\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import base64\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlHl3bnkFPZ"
      },
      "outputs": [],
      "source": [
        "# Set these (run this cell to verify the output)\n",
        "\n",
        "bigquery_location = \"us\"\n",
        "region = \"us-central1\"\n",
        "\n",
        "# Get some values using gcloud\n",
        "project_id = !(gcloud config get-value project)\n",
        "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
        "\n",
        "if len(project_id) != 1:\n",
        "  raise RuntimeError(f\"project_id is not set: {project_id}\")\n",
        "project_id = project_id[0]\n",
        "\n",
        "if len(user) != 1:\n",
        "  raise RuntimeError(f\"user is not set: {user}\")\n",
        "user = user[0]\n",
        "\n",
        "print(f\"project_id = {project_id}\")\n",
        "print(f\"user = {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### Helper Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2j3ARDYynWn"
      },
      "source": [
        "#### Gemini Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyD-A_QQyxBL"
      },
      "outputs": [],
      "source": [
        "def GeminiLLM(prompt, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": {\n",
        "          \"text\": prompt\n",
        "      },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ndOu9GkyoBJ"
      },
      "source": [
        "#### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdPlK0kzeCuI"
      },
      "outputs": [],
      "source": [
        "def RunQuery(sql):\n",
        "  import time\n",
        "  from google.cloud import bigquery\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
        "      df_result = client.query(sql).to_dataframe()\n",
        "      return df_result\n",
        "  else:\n",
        "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
        "    query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "    # Check on the progress by getting the job's updated state.\n",
        "    query_job = client.get_job(\n",
        "        query_job.job_id, location=query_job.location\n",
        "    )\n",
        "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    while query_job.state != \"DONE\":\n",
        "      time.sleep(2)\n",
        "      query_job = client.get_job(\n",
        "          query_job.job_id, location=query_job.location\n",
        "          )\n",
        "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    if query_job.error_result == None:\n",
        "      return True\n",
        "    else:\n",
        "      raise Exception(query_job.error_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRgDAjN9gsg9"
      },
      "outputs": [],
      "source": [
        "# Since our Primary keys are INTs we get the next available value\n",
        "def GetNextPrimaryKey(fully_qualified_table_name, field_name):\n",
        "  import time\n",
        "  from google.cloud import bigquery\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  sql = f\"\"\"\n",
        "  SELECT IFNULL(MAX({field_name}),0) AS result\n",
        "    FROM `{fully_qualified_table_name}`\n",
        "  \"\"\"\n",
        "  # print(sql)\n",
        "  df_result = client.query(sql).to_dataframe()\n",
        "  # display(df_result)\n",
        "  return df_result['result'].iloc[0] + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-WI70Wqyssc"
      },
      "outputs": [],
      "source": [
        "def PrettyPrintJson(json_string):\n",
        "  json_object = json.loads(json_string)\n",
        "  json_formatted_str = json.dumps(json_object, indent=2)\n",
        "  print(json_formatted_str)\n",
        "  return json.dumps(json_object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYRHDPdVKBzd"
      },
      "source": [
        "### Main Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKJr7o-cg3FE"
      },
      "source": [
        "#### Create BigQuery table to hold results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5t-WixKg2Or"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "\n",
        "--DROP TABLE IF EXISTS `chocolate_ai.data_insights`;\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `chocolate_ai.data_insights`\n",
        "(\n",
        "    data_insights_id                  INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "    data_insights_scan_name           STRING  NOT NULL OPTIONS(description=\"The name of the data insights scan.\"),\n",
        "    data_insights_dataset_name        STRING  NOT NULL OPTIONS(description=\"The name of the data insights dataset.\"),\n",
        "    data_insights_table_name          STRING  NOT NULL OPTIONS(description=\"The name of the data insights table.\"),\n",
        "\n",
        "    data_insights_sql                 STRING  NOT NULL OPTIONS(description=\"The generated SQL by data insights\"),\n",
        "    data_insights_sql_description     STRING  NOT NULL OPTIONS(description=\"The generated Description by data insights\"),\n",
        ")\n",
        "CLUSTER BY data_insights_scan_name;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no0x5CHub1IU"
      },
      "source": [
        "#### createDataDocumentScan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IivdMckQS4i4"
      },
      "outputs": [],
      "source": [
        "def createDataDocumentScan(data_insights_scan_name, data_insights_display_name, data_insights_dataset_name, data_insights_data_scan_table_name):\n",
        "  \"\"\"Tests to see if the Document (not a data profile or data quality) scan is created and if not, creates it.\"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  !curl \\\n",
        "    'https://dataplex.googleapis.com/v1/projects/data-analytics-preview/locations/us-central1/dataScans' \\\n",
        "    --header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "    --header 'Accept: application/json' \\\n",
        "    --compressed\n",
        "  {\n",
        "        \"name\": \"projects/data-analytics-preview/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan\",\n",
        "        \"uid\": \"4654c390-a841-4939-bd0b-8ba2d151bd03\",\n",
        "        \"displayName\": \"Chocolate A.I. - Looker Sales Data Documenation Scan\",\n",
        "        \"state\": \"ACTIVE\",\n",
        "        \"createTime\": \"2024-08-22T18:07:50.455838572Z\",\n",
        "        \"updateTime\": \"2024-08-22T18:07:55.294013073Z\",\n",
        "        \"data\": {\n",
        "          \"resource\": \"//bigquery.googleapis.com/projects/data-analytics-preview/datasets/chocolate_ai/tables/looker_sales_data\"\n",
        "        },\n",
        "        \"executionSpec\": {\n",
        "          \"trigger\": {\n",
        "            \"onDemand\": {}\n",
        "          }\n",
        "        },\n",
        "        \"executionStatus\": {},\n",
        "        \"type\": \"DATA_DOCUMENTATION\"\n",
        "      },\n",
        "  \"\"\"\n",
        "\n",
        "  # Gather existing data scans\n",
        "  # https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.dataScans/list\n",
        "\n",
        "  url = f\"https://dataplex.googleapis.com/v1/projects/{project_id}/locations/{region}/dataScans\"\n",
        "\n",
        "  # Gather existing data scans\n",
        "  json_result = restAPIHelper(url, \"GET\", None)\n",
        "  print(f\"createDataDocumentScan (GET) json_result: {json_result}\")\n",
        "\n",
        "  # Test to see if data scan exists, if so return\n",
        "  if \"dataScans\" in json_result:\n",
        "    for item in json_result[\"dataScans\"]:\n",
        "      print(f\"Scan names: {item['name']}\")\n",
        "      # \"projects/data-analytics-preview/locations/us-central1/clusters/kafka-cluster\"\n",
        "      if item[\"name\"] == f\"projects/{project_id}/locations/{region}/dataScans/{data_insights_scan_name}\":\n",
        "        print(f\"Data Document Scan {data_insights_scan_name} already exists\")\n",
        "        return f\"projects/{project_id}/locations/{region}/dataScans/{data_insights_scan_name}\"\n",
        "\n",
        "  \"\"\"\n",
        "  # Create a Documentation Scan\n",
        "  # Create\n",
        "  #\n",
        "  !curl --request POST \\\n",
        "    'https://dataplex.googleapis.com/v1/projects/data-analytics-preview/locations/us-central1/dataScans?dataScanId=chocolate-ai-looker-sales-data-docuemnt-scan' \\\n",
        "    --header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "    --header 'Accept: application/json' \\\n",
        "    --header 'Content-Type: application/json' \\\n",
        "    --data '{\"displayName\":\"Chocolate A.I. - Looker Sales Data Documenation Scan\",\"type\": \"DATA_DOCUMENTATION\",  \"dataDocumentationSpec\": {}, \"data\":{\"resource\":\"//bigquery.googleapis.com/projects/data-analytics-preview/datasets/chocolate_ai/tables/looker_sales_data\"}}' \\\n",
        "    --compressed\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a new scan\n",
        "  # https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.dataScans/create\n",
        "  print(\"Creating Document Data Scan\")\n",
        "\n",
        "  url = f\"https://dataplex.googleapis.com/v1/projects/{project_id}/locations/{region}/dataScans?dataScanId={data_insights_scan_name}\"\n",
        "\n",
        "  request_body = {\n",
        "      \"displayName\": data_insights_display_name,\n",
        "      \"type\": \"DATA_DOCUMENTATION\",\n",
        "      \"dataDocumentationSpec\": {},\n",
        "      \"data\":{\n",
        "          \"resource\": f\"//bigquery.googleapis.com/projects/{project_id}/datasets/{data_insights_dataset_name}/tables/{data_insights_data_scan_table_name}\"\n",
        "          }\n",
        "      }\n",
        "\n",
        "  \"\"\"\n",
        "  {\n",
        "    \"name\": \"projects/data-analytics-preview/locations/us-central1/operations/operation-1724350067868-62049894382d1-169e9f87-1fe5b7b6\",\n",
        "    \"metadata\": {\n",
        "      \"@type\": \"type.googleapis.com/google.cloud.dataplex.v1.OperationMetadata\",\n",
        "      \"createTime\": \"2024-08-22T18:07:50.460547819Z\",\n",
        "      \"target\": \"projects/data-analytics-preview/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan\",\n",
        "      \"verb\": \"create\",\n",
        "      \"requestedCancellation\": false,\n",
        "      \"apiVersion\": \"v1\"\n",
        "    },\n",
        "    \"done\": false\n",
        "  }\n",
        "  \"\"\"\n",
        "\n",
        "  json_result = restAPIHelper(url, \"POST\", request_body)\n",
        "\n",
        "  name = json_result[\"metadata\"][\"target\"]\n",
        "  print(f\"Document Data Scan created: {name}\")\n",
        "  return name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVqzTz8qb7PB"
      },
      "source": [
        "#### runDataDocumentScan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZDnRyphYdVL"
      },
      "outputs": [],
      "source": [
        "def runDataDocumentScan(data_insights_scan_name):\n",
        "  \"\"\"Runs the data document scan job and monitors until it completes\"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  !curl --request POST \\\n",
        "    'https://dataplex.googleapis.com/v1/projects/data-analytics-preview/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan:run' \\\n",
        "    --header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "    --header 'Accept: application/json' \\\n",
        "    --header 'Content-Type: application/json' \\\n",
        "    --data '{}' \\\n",
        "    --compressed\n",
        "  \"\"\"\n",
        "\n",
        "  # Create a new scan\n",
        "  # https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.dataScans/run\n",
        "  print(\"Creating Document Data Scan Run\")\n",
        "\n",
        "  url = f\"https://dataplex.googleapis.com/v1/projects/{project_id}/locations/{region}/dataScans/{data_insights_scan_name}:run\"\n",
        "\n",
        "  request_body = { }\n",
        "\n",
        "  \"\"\"\n",
        "  {\n",
        "    \"job\": {\n",
        "      \"name\": \"projects/756740881369/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan/jobs/27115210-eaf8-43f2-80e8-b2681daa07f0\",\n",
        "      \"uid\": \"27115210-eaf8-43f2-80e8-b2681daa07f0\",\n",
        "      \"state\": \"PENDING\",\n",
        "      \"type\": \"DATA_DOCUMENTATION\",\n",
        "      \"createTime\": \"1970-01-01T00:00:00Z\",\n",
        "      \"dataDocumentationSpec\": {}\n",
        "    }\n",
        "  }\n",
        "  \"\"\"\n",
        "\n",
        "  json_result = restAPIHelper(url, \"POST\", request_body)\n",
        "  job_name = json_result[\"job\"][\"name\"]\n",
        "  job_state = json_result[\"job\"][\"state\"]\n",
        "  print(f\"Document Data Scan Run created: {job_name} - State: {job_state}\")\n",
        "\n",
        "  # Monitor the job until it completes\n",
        "  \"\"\"\n",
        "  !curl \\\n",
        "    'https://dataplex.googleapis.com/v1/projects/756740881369/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan/jobs/27115210-eaf8-43f2-80e8-b2681daa07f0' \\\n",
        "    --header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "    --header 'Accept: application/json' \\\n",
        "    --compressed\n",
        "\n",
        "  {\n",
        "    \"name\": \"projects/756740881369/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan/jobs/27115210-eaf8-43f2-80e8-b2681daa07f0\",\n",
        "    \"uid\": \"27115210-eaf8-43f2-80e8-b2681daa07f0\",\n",
        "    \"startTime\": \"2024-08-22T18:12:17.553066314Z\",\n",
        "    \"endTime\": \"2024-08-22T18:13:06.541798260Z\",\n",
        "    \"state\": \"SUCCEEDED\",\n",
        "    \"type\": \"DATA_DOCUMENTATION\",\n",
        "    \"createTime\": \"2024-08-22T18:12:17.553025391Z\"\n",
        "  }\n",
        "  STATE_UNSPECIFIED\tThe DataScanJob state is unspecified.\n",
        "  RUNNING\tThe DataScanJob is running.\n",
        "  CANCELING\tThe DataScanJob is canceling.\n",
        "  CANCELLED\tThe DataScanJob cancellation was successful.\n",
        "  SUCCEEDED\tThe DataScanJob completed successfully.\n",
        "  FAILED\tThe DataScanJob is no longer running due to an error.\n",
        "  PENDING\tThe DataScanJob has been created but not started to run yet.\n",
        "  \"\"\"\n",
        "\n",
        "  url = f\"https://dataplex.googleapis.com/v1/{job_name}\"\n",
        "  json_result = restAPIHelper(url, \"GET\", None)\n",
        "  while json_result[\"state\"] == \"STATE_UNSPECIFIED\" or json_result[\"state\"] == \"RUNNING\" or json_result[\"state\"] == \"PENDING\":\n",
        "    print(f\"Document Data Scan Run {job_name} - State: {json_result['state']}\")\n",
        "    time.sleep(10)\n",
        "    json_result = restAPIHelper(url, \"GET\", None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC6-LnNob90k"
      },
      "source": [
        "#### getDataDocumentScanSql"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW6fmTRdW4km"
      },
      "outputs": [],
      "source": [
        "def getDataDocumentScanSql(data_insights_scan_name, data_insights_dataset_name,data_insights_data_scan_table_name, data_insight_id_starting_key):\n",
        "  \"\"\"Gets the results of the document scan.  If there are no results, then run the job to create the results.\"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "  !curl \\\n",
        "  'https://dataplex.googleapis.com/v1/projects/data-analytics-preview/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan?view=FULL' \\\n",
        "  --header \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  --header 'Accept: application/json' \\\n",
        "  --compressed\n",
        "\n",
        "  {\n",
        "    \"name\": \"projects/data-analytics-preview/locations/us-central1/dataScans/chocolate-ai-looker-sales-data-docuemnt-scan\",\n",
        "    \"uid\": \"4654c390-a841-4939-bd0b-8ba2d151bd03\",\n",
        "    \"displayName\": \"Chocolate A.I. - Looker Sales Data Documenation Scan\",\n",
        "    \"state\": \"ACTIVE\",\n",
        "    \"createTime\": \"2024-08-22T18:07:50.455838572Z\",\n",
        "    \"updateTime\": \"2024-08-22T18:07:55.294013073Z\",\n",
        "    \"data\": {\n",
        "      \"resource\": \"//bigquery.googleapis.com/projects/data-analytics-preview/datasets/chocolate_ai/tables/looker_sales_data\"\n",
        "    },\n",
        "    \"executionSpec\": {\n",
        "      \"trigger\": {\n",
        "        \"onDemand\": {}\n",
        "      }\n",
        "    },\n",
        "    \"executionStatus\": {\n",
        "      \"latestJobStartTime\": \"2024-08-22T18:12:17.553066314Z\",\n",
        "      \"latestJobEndTime\": \"2024-08-22T18:13:06.541798260Z\",\n",
        "      \"latestJobCreateTime\": \"2024-08-22T18:12:17.553025391Z\"\n",
        "    },\n",
        "    \"type\": \"DATA_DOCUMENTATION\",\n",
        "    \"dataDocumentationSpec\": {},\n",
        "    \"dataDocumentationResult\": {\n",
        "      \"queries\": [\n",
        "        {\n",
        "          \"sql\": \"SELECT company_name, item_name, city_name, item_size, customer_name, sale_date, SUM(sale_price) AS total_sale_price FROM `chocolate_ai.looker_sales_data` GROUP BY company_name, item_name, city_name, item_size, customer_name, sale_date;\",\n",
        "          \"description\": \"What is the total sale price of each item name for each company in each city for each item size for each customer name for each sale date?\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  }\n",
        "  \"\"\"\n",
        "\n",
        "  # First find the cluster if it scan exists\n",
        "  # https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.dataScans/list\n",
        "\n",
        "  url = f\"https://dataplex.googleapis.com/v1/projects/{project_id}/locations/{region}/dataScans/{data_insights_scan_name}?view=FULL\"\n",
        "\n",
        "  # Gather existing clusters\n",
        "  json_result = restAPIHelper(url, \"GET\", None)\n",
        "  print(f\"createDataDocumentScan (GET) json_result: {json_result}\")\n",
        "\n",
        "  # Test to see if cluster exists, if so return\n",
        "  data_insights_list = []\n",
        "  if \"name\" in json_result:\n",
        "    if \"dataDocumentationResult\" in json_result:\n",
        "      for item in json_result[\"dataDocumentationResult\"][\"queries\"]:\n",
        "        result_dict = {\n",
        "            \"data_insights_id\" : data_insight_id_starting_key,\n",
        "            \"data_insights_scan_name\" : data_insights_scan_name,\n",
        "            \"data_insights_dataset_name\" : data_insights_dataset_name,\n",
        "            \"data_insights_table_name\" : data_insights_table_name,\n",
        "            \"data_insights_sql\": item[\"sql\"],\n",
        "            \"data_insights_sql_description\": item[\"description\"]\n",
        "            }\n",
        "        data_insight_id_starting_key += 1\n",
        "        data_insights_list.append(result_dict)\n",
        "    else:\n",
        "      print(\"Need to run a job\")\n",
        "      runDataDocumentScan(data_insights_scan_name)\n",
        "      json_result = restAPIHelper(url, \"GET\", None)\n",
        "      if \"name\" in json_result:\n",
        "        if \"dataDocumentationResult\" in json_result:\n",
        "          for item in json_result[\"dataDocumentationResult\"][\"queries\"]:\n",
        "            result_dict = {\n",
        "                \"data_insights_id\" : data_insight_id_starting_key,\n",
        "                \"data_insights_scan_name\" : data_insights_scan_name,\n",
        "                \"data_insights_dataset_name\" : data_insights_dataset_name,\n",
        "                \"data_insights_table_name\" : data_insights_table_name,\n",
        "                \"data_insights_sql\": item[\"sql\"],\n",
        "                \"data_insights_sql_description\": item[\"description\"]\n",
        "                }\n",
        "            data_insight_id_starting_key += 1\n",
        "            data_insights_list.append(result_dict)\n",
        "\n",
        "  return data_insights_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Luj-kVQcBBU"
      },
      "source": [
        "#### Create the document scan, the scan job and return the data insights results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttzYqec9WL46"
      },
      "outputs": [],
      "source": [
        "data_insights_scan_name = \"looker-sales-data-data-documentation-scan\"\n",
        "data_insights_display_name = \"looker_sales_data-data-documentation-scan\" # This triggers the BigQuery UI to show the results\n",
        "data_insights_dataset_name = \"chocolate_ai\"\n",
        "data_insights_data_scan_table_name = \"looker_sales_data\"\n",
        "\n",
        "data_document_uri = createDataDocumentScan(data_insights_scan_name, data_insights_display_name, data_insights_dataset_name, data_insights_data_scan_table_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txLztYEeXxQj"
      },
      "outputs": [],
      "source": [
        "data_insights_table_name = \"data_insights\"\n",
        "data_insights_table_primary_key = \"data_insights_id\"\n",
        "\n",
        "data_insight_id_starting_key = GetNextPrimaryKey(f\"{project_id}.{data_insights_dataset_name}.{data_insights_table_name}\", data_insights_table_primary_key)\n",
        "\n",
        "data_insights_list = getDataDocumentScanSql(data_insights_scan_name, data_insights_dataset_name, data_insights_table_name, data_insight_id_starting_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jjlHPX_eGWP"
      },
      "source": [
        "#### Save results to BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3kgxRsPeWbR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "\n",
        "bigquery_client = bigquery.Client()\n",
        "\n",
        "# Bulk insert the results\n",
        "table_id = f\"{project_id}.chocolate_ai.data_insights\"\n",
        "\n",
        "dataframe = pd.DataFrame(\n",
        "    pd.DataFrame(data_insights_list), # Your source data\n",
        "    columns=[\n",
        "        \"data_insights_id\",\n",
        "        \"data_insights_scan_name\",\n",
        "        \"data_insights_dataset_name\",\n",
        "        \"data_insights_table_name\",\n",
        "        \"data_insights_sql\",\n",
        "        \"data_insights_sql_description\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=[\n",
        "        bigquery.SchemaField(\"data_insights_id\", bigquery.enums.SqlTypeNames.INT64, mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"data_insights_scan_name\", bigquery.enums.SqlTypeNames.STRING, mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"data_insights_dataset_name\", bigquery.enums.SqlTypeNames.STRING, mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"data_insights_table_name\", bigquery.enums.SqlTypeNames.STRING, mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"data_insights_sql\", bigquery.enums.SqlTypeNames.STRING, mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"data_insights_sql_description\", bigquery.enums.SqlTypeNames.STRING, mode=\"REQUIRED\"),\n",
        "    ],\n",
        "    write_disposition=\"WRITE_APPEND\",\n",
        ")\n",
        "\n",
        "job = bigquery_client.load_table_from_dataframe(dataframe, table_id, job_config=job_config)\n",
        "job.result()  # Wait for the job to complete.\n",
        "\n",
        "table = bigquery_client.get_table(table_id)  # Make an API request.\n",
        "print(\"Loaded {} rows and {} columns to {}\".format(table.num_rows, len(table.schema), table_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JLSv3Dvd3mA"
      },
      "outputs": [],
      "source": [
        "%%bigquery\n",
        "\n",
        "SELECT * FROM `chocolate_ai.data_insights` ORDER BY data_insights_id;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLdLjaHg0Jhy"
      },
      "source": [
        "#### Update BigQuery (Console) to see these Insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4goQllt3a5L"
      },
      "source": [
        "##### updateBigQueryTableInsightsLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw3LXTC-0HOx"
      },
      "outputs": [],
      "source": [
        "def updateBigQueryTableInsightsLabels(data_insights_scan_id, data_insights_dataset_name, data_insights_data_scan_table_name):\n",
        "  \"\"\"Sets the labels on the BigQuery table so users can see the data insights in the Console.\"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "    curl --request PATCH \\\n",
        "        \"https://bigquery.googleapis.com/bigquery/v2/projects/{local_project_id}/datasets/{local_dataset_name}/tables/{local_table_name}\" \\\n",
        "        --header \"Authorization: Bearer $token\" \\\n",
        "        --header \"Accept: application/json\" \\\n",
        "        --header \"Content-Type: application/json\" \\\n",
        "        --data \"{\n",
        "          \\\"labels\\\":\n",
        "          {\\\"dataplex-dp-published-location\\\":\\\"{local_dataplex_region}\\\",\n",
        "          \\\"dataplex-dp-published-project\\\":\\\"{local_project_id}\\\",\n",
        "          \\\"dataplex-dp-published-scan\\\":\\\"{local_scan_name}\\\"}}\" \\\n",
        "        --compressed\n",
        "  \"\"\"\n",
        "\n",
        "  # Patch BigQuery\n",
        "  # https://cloud.google.com/dataplex/docs/reference/rest/v1/projects.locations.dataScans/create\n",
        "  print(\"Patching BigQuery Data Insights Labels\")\n",
        "\n",
        "  url = f\"https://bigquery.googleapis.com/bigquery/v2/projects/{project_id}/datasets/{data_insights_dataset_name}/tables/{data_insights_data_scan_table_name}\"\n",
        "\n",
        "  request_body = {\n",
        "      \"labels\" : {\n",
        "          \"dataplex-data-documentation-published-location\" : region,\n",
        "          \"dataplex-data-documentation-published-project\" : project_id,\n",
        "          \"dataplex-data-documentation-published-scan\" : data_insights_scan_id,\n",
        "          }\n",
        "      }\n",
        "\n",
        "  json_result = restAPIHelper(url, \"PATCH\", request_body)\n",
        "  print(json_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DOZQ0j-3fnT"
      },
      "source": [
        "##### Patch the BigQuery table so the Data Insights show in the UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk6hS8u4ypk4"
      },
      "outputs": [],
      "source": [
        "# This will tell the BigQuery UI about this data document scan and the results will also show in the BQ UI\n",
        "updateBigQueryTableInsightsLabels(data_insights_scan_name, data_insights_dataset_name, data_insights_data_scan_table_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IxhtRRrvR-"
      },
      "source": [
        "### Clean Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lF2Z7skFbvf"
      },
      "outputs": [],
      "source": [
        "# Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQ2BPisXDA0"
      },
      "source": [
        "### Reference Links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2grorb1x8KFU"
      },
      "source": [
        "- [Google.com](https://www.google.com)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "sZ6m_wGrK0YG",
        "JbOjdSP1kN9T",
        "Q2j3ARDYynWn",
        "4ndOu9GkyoBJ",
        "nKJr7o-cg3FE",
        "no0x5CHub1IU",
        "MVqzTz8qb7PB",
        "DC6-LnNob90k",
        "8Luj-kVQcBBU",
        "7jjlHPX_eGWP",
        "cLdLjaHg0Jhy",
        "D4goQllt3a5L",
        "5DOZQ0j-3fnT",
        "42IxhtRRrvR-",
        "ASQ2BPisXDA0"
      ],
      "name": "DB-GMA-Campaign-Performance-Insights.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
