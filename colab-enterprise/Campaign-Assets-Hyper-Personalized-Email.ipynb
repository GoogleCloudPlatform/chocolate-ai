{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### To Do / License\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l85J9wppHuh3"
      },
      "source": [
        "- For 5 users\n",
        "\n",
        "- Input: Marketing campaign details\n",
        "\n",
        "- Generate a custom image for a marketing campaign based upon their profile\n",
        "  - Gemini needs to explain its reasoning\n",
        "```\n",
        "Generate a LLM Prompt to generate a marketing image to attact the attention to our Mocha Magic coffee drink based upon the customer's profile (in Json).\n",
        "We are a coffee truck company called Chocolate A.I..\n",
        "We want the image to be specific to this customer and their interests.\n",
        "Think creatively and use the customer's interests to create a unique image.\n",
        "Make sure you state the image should be photo realistic.\n",
        "Avoid and copyrighted names such as sporting teams names.\n",
        "{\"children\":\"Yes\",\"coffee_preferences\":[\"French Press\"],\"content_interaction\":[\"Social media engagement - high\"],\"customer_age\":44,\"customer_id\":1,\"customer_service_interactions\":[],\"dietary_preferences\":[],\"education\":\"Master of Fine Arts (MFA)\",\"facebook_bio\":\"\",\"facebook_handle\":\"\",\"instagram_bio\":\"\",\"instagram_handle\":\"\",\"interests\":[\"Photography\",\"Ceramics\",\"Pottery\",\"Hiking\"],\"lifestyle\":[\"Creative\",\"Outdoorsy\",\"Balanced\"],\"linkedin_bio\":\"Art educator passionate about fostering creativity and critical thinking skills in young minds. Experienced in curriculum development, classroom management, and arts integration. Seeking opportunities to collaborate with fellow educators and contribute to innovative art education initiatives.\",\"linkedin_engagement\":\"Passive\",\"linkedin_handle\":\"william-jones-art-educator\",\"martial_status\":\"Married\",\"occupation\":\"Art Teacher\",\"solicated_buying_habits\":[\"Special Occasions\"],\"sports\":[\"San Francisco Giants\"],\"tiktok_bio\":\"\",\"tiktok_handle\":\"\",\"twitter_bio\":\"\",\"twitter_engagement\":\"\",\"twitter_handle\":\"\",\"youtube_bio\":\"\",\"youtube_engagement\":\"\",\"youtube_handle\":\"\"}\n",
        "```\n",
        "\n",
        "- Pattern to show:\n",
        "  1. Generate a basic prompt\n",
        "  2. Have Gemini rewrite your prompt (better detail)\n",
        "  3. Call Imagen3 with the updated prompt\n",
        "  4. Pass the image back to Gemini Vision to verify the image meets the basic prompt\n",
        "\n",
        "- Generate the marketing text\n",
        "\n",
        "- Translate the text to different lanaguage\n",
        "  1. Call Gemini to translate the text\n",
        "  2. Pass the text back to Gemini to verify it is proper in that lanuage and is actually in the language\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```\n",
        "\n",
        "Author: Adam Paternostro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX"
      },
      "outputs": [],
      "source": [
        "# To read/write to/from Kafka\n",
        "import sys\n",
        "\n",
        "# https://PLACEHOLDER.com/index.html\n",
        "# !{sys.executable} -m pip install PLACEHOLDER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyL-Rg4Dr_f"
      },
      "source": [
        "### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYsEVSXp6IP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "import IPython.display\n",
        "import google.auth\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import base64\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import base64\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlHl3bnkFPZ"
      },
      "outputs": [],
      "source": [
        "# Set these (run this cell to verify the output)\n",
        "\n",
        "bigquery_location = \"us\"\n",
        "region = \"us-central1\"\n",
        "location = \"us-central1\"\n",
        "storage_account = \"data-analytics-preview\"\n",
        "\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "# Format the date and time as desired\n",
        "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "gemini_languages = [\"Arabic (ar)\",  \"Bengali (bn)\",  \"Bulgarian (bg)\",  \"Chinese simplified (zh)\",  \"Chinese traditional (zh)\",\n",
        "  \"Croatian (hr)\",  \"Czech (cs)\",  \"Danish (da)\",  \"Dutch (nl)\",  \"Estonian (et)\",  \"Finnish (fi)\",  \"French (fr)\",\n",
        "  \"German (de)\",  \"Greek (el)\",  \"Hebrew (iw)\",  \"Hindi (hi)\",  \"Hungarian (hu)\",  \"Indonesian (id)\",  \"Italian (it)\",  \"Japanese (ja)\",\n",
        "  \"Korean (ko)\",  \"Latvian (lv)\",  \"Lithuanian (lt)\",  \"Norwegian (no)\",  \"Polish (pl)\",  \"Portuguese (pt)\",  \"Romanian (ro)\",  \"Russian (ru)\",\n",
        "  \"Serbian (sr)\",  \"Slovak (sk)\",  \"Slovenian (sl)\",  \"Spanish (es)\",  \"Swahili (sw)\",  \"Swedish (sv)\",  \"Thai (th)\",  \"Turkish (tr)\",  \"Ukrainian (uk)\",\n",
        "  \"Vietnamese (vi)\"]\n",
        "\n",
        "# Get some values using gcloud\n",
        "project_id = !(gcloud config get-value project)\n",
        "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
        "\n",
        "if len(project_id) != 1:\n",
        "  raise RuntimeError(f\"project_id is not set: {project_id}\")\n",
        "project_id = project_id[0]\n",
        "\n",
        "if len(user) != 1:\n",
        "  raise RuntimeError(f\"user is not set: {user}\")\n",
        "user = user[0]\n",
        "\n",
        "print(f\"project_id = {project_id}\")\n",
        "print(f\"user = {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### Helper Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imagen3 Image Generation"
      ],
      "metadata": {
        "id": "3Q7UAkst0phu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ImageGen(prompt):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  model_version = \"imagen-3.0-generate-001\" # imagen-3.0-fast-generate-001\n",
        "  #model_version = \"imagen-3.0-generate-preview-0611\" # Preview Access Model\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-generation\n",
        "  # url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/imagegeneration:predict\"\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/{model_version}:predict\"\n",
        "\n",
        "  payload = {\n",
        "    \"instances\": [\n",
        "      {\n",
        "        \"prompt\": prompt\n",
        "      }\n",
        "    ],\n",
        "    \"parameters\": {\n",
        "      \"sampleCount\": 1,\n",
        "      \"personGeneration\" : \"allow_adult\"  # Google users will get an error due to an org policy\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    response_json = json.loads(response.content)\n",
        "    print(f\"Imagen3 response_json: {response_json}\")\n",
        "\n",
        "    if \"blocked\" in response_json:\n",
        "      print(f\"Blocked: {response_json['blocked']}\")\n",
        "\n",
        "    if \"predictions\" in response_json:\n",
        "      image_data = response_json[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "      image_data = base64.b64decode(image_data)\n",
        "      filename= str(uuid.uuid4()) + \".png\"\n",
        "      with open(filename, \"wb\") as f:\n",
        "        f.write(image_data)\n",
        "      print(f\"Image generated OK.\")\n",
        "      return filename\n",
        "    else:\n",
        "      raise RuntimeError(f\"No predictions in response: {response.content}\")\n",
        "  else:\n",
        "    error = f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ],
      "metadata": {
        "id": "OjHSz0k20sgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gemini LLM (Pro 1.0 , Pro 1.5)"
      ],
      "metadata": {
        "id": "vOFTk6sj1YIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GeminiLLM(prompt, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": {\n",
        "          \"text\": prompt\n",
        "      },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ],
      "metadata": {
        "id": "xHit3Hh-1ZAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GeminiLLM_VerifyImage(prompt, imageBase64, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "          { \"text\": prompt },\n",
        "          { \"inlineData\": {  \"mimeType\": \"image/png\", \"data\": f\"{imageBase64}\" } }\n",
        "        ]\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ],
      "metadata": {
        "id": "rWXSCd5VCPjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "bI-KJELZ1jgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RunQuery(sql):\n",
        "  import time\n",
        "  from google.cloud import bigquery\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
        "      df_result = client.query(sql).to_dataframe()\n",
        "      return df_result\n",
        "  else:\n",
        "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
        "    query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "    # Check on the progress by getting the job's updated state.\n",
        "    query_job = client.get_job(\n",
        "        query_job.job_id, location=query_job.location\n",
        "    )\n",
        "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    while query_job.state != \"DONE\":\n",
        "      time.sleep(2)\n",
        "      query_job = client.get_job(\n",
        "          query_job.job_id, location=query_job.location\n",
        "          )\n",
        "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    if query_job.error_result == None:\n",
        "      return True\n",
        "    else:\n",
        "      raise Exception(query_job.error_result)"
      ],
      "metadata": {
        "id": "pmnCwYvA1kZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_png_to_base64(image_path):\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  # Convert the image to a base64 string.\n",
        "  _, buffer = cv2.imencode('.png', image)\n",
        "  base64_string = base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "  return base64_string"
      ],
      "metadata": {
        "id": "_OAO_-LC1k3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PrettyPrintJson(json_string):\n",
        "  json_object = json.loads(json_string)\n",
        "  json_formatted_str = json.dumps(json_object, indent=2)\n",
        "  print(json_formatted_str)\n",
        "  return json.dumps(json_object)"
      ],
      "metadata": {
        "id": "VNAmwvAf1knl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This was generated by GenAI\n",
        "\n",
        "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
        "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
        "\n",
        "  Args:\n",
        "      local_file_path: The full path to the local file.\n",
        "      bucket_name: The name of the GCS bucket to upload to.\n",
        "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  import os\n",
        "  from google.cloud import storage\n",
        "\n",
        "  # Ensure the file exists locally\n",
        "  if not os.path.exists(local_file_path):\n",
        "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
        "\n",
        "  # Create a storage client\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  # Get a reference to the bucket\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "  # Create a blob object with the desired destination path\n",
        "  blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "  # Upload the file from the local filesystem\n",
        "  content_type = \"\"\n",
        "  if local_file_path.endswith(\".html\"):\n",
        "    content_type = \"text/html; charset=utf-8\"\n",
        "\n",
        "  if local_file_path.endswith(\".json\"):\n",
        "    content_type = \"application/json; charset=utf-8\"\n",
        "\n",
        "  if content_type == \"\":\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "  else:\n",
        "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
        "\n",
        "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\")"
      ],
      "metadata": {
        "id": "BljTy6yYaIp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYRHDPdVKBzd"
      },
      "source": [
        "### BigQuery Table and Preview Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "\n",
        "DROP TABLE IF EXISTS `chocolate_ai.customer_hyper_personalized_email`;\n",
        "\n",
        "CREATE TABLE IF NOT EXISTS `chocolate_ai.customer_hyper_personalized_email`\n",
        "(\n",
        "    customer_id                                    INTEGER NOT NULL OPTIONS(description=\"Primary key.\"),\n",
        "\n",
        "    llm_marketing_prompt                           STRING  OPTIONS(description=\"The prompt to generate the marketing email text.\"),\n",
        "    llm_marketing_prompt_response_json             JSON    OPTIONS(description=\"The response from the llm marketing prompt in json.\"),\n",
        "    llm_marketing_prompt_response_text             STRING  OPTIONS(description=\"The response from the llm marketing prompt in text.\"),\n",
        "\n",
        "    llm_orginial_image_prompt                      STRING  OPTIONS(description=\"The prompt to generate the original image text.\"),\n",
        "    llm_orginial_image_prompt_response_json        JSON    OPTIONS(description=\"The response from the llm original prompt in json.\"),\n",
        "    llm_orginial_image_prompt_response_text        STRING  OPTIONS(description=\"The response from the llm original prompt in text.\"),\n",
        "\n",
        "    llm_improved_image_prompt                      STRING  OPTIONS(description=\"The prompt to generate the improved image text.\"),\n",
        "    -- The improved prompt will be passed to Imagen3\n",
        "    --llm_improved_image_prompt_response_json      JSON    OPTIONS(description=\"The response from the llm improved prompt in json.\"),\n",
        "    --llm_improved_image_prompt_response_text      STRING  OPTIONS(description=\"The response from the llm improved prompt in text.\"),\n",
        "\n",
        "    llm_verify_image_prompt                        STRING  OPTIONS(description=\"The prompt to verify the generated image.\"),\n",
        "    llm_verify_image_response_json                 JSON    OPTIONS(description=\"The response from verify the generated image in json.\"),\n",
        "    llm_verify_image_text                          STRING  OPTIONS(description=\"The response from verify the generated image in text.\"),\n",
        "\n",
        "    llm_translation_language_prompt                STRING  OPTIONS(description=\"The prompt to generate the secondary lanagage text.\"),\n",
        "    llm_translation_language_prompt_response_json  JSON    OPTIONS(description=\"The response from the llm secondary lanagage prompt in json.\"),\n",
        "    llm_translation_language_prompt_response_text  STRING  OPTIONS(description=\"The response from the llm secondary lanagage prompt in text.\"),\n",
        "\n",
        "    llm_validate_translation_prompt                STRING  OPTIONS(description=\"The prompt to generate the vadiation of the translation text.\"),\n",
        "    llm_validate_translation_prompt_response_json  JSON    OPTIONS(description=\"The response from the llm vadiation of the translation prompt in json.\"),\n",
        "    llm_validate_translation_prompt_response_text  STRING  OPTIONS(description=\"The response from the llm vadiation of the translation prompt in text.\"),\n",
        "\n",
        "    image_gcs_filename                             STRING  OPTIONS(description=\"The GCS path for the marketing campaign image.\"),\n",
        "    image_http_url                                 STRING  OPTIONS(description=\"The HTTP path for the marketing campaign image.\"),\n",
        "    image_generated                                BOOLEAN OPTIONS(description=\"Has the image been generated and saved to GCS.\"),\n",
        "    image_verified                                 BOOLEAN OPTIONS(description=\"Did the image pass verification.\"),\n",
        "\n",
        "    html_gcs_filename                              STRING  OPTIONS(description=\"The GCS path for the marketing campaign HTML file.\"),\n",
        "    html_http_url                                  STRING  OPTIONS(description=\"The HTTP path for the marketing campaign HTML file.\"),\n",
        "    html_generated                                 BOOLEAN OPTIONS(description=\"Has the HTML been generated and saved to GCS.\"),\n",
        "    translation_verified                           BOOLEAN OPTIONS(description=\"Did the translation pass verification.\"),\n",
        ")\n",
        "CLUSTER BY customer_id;"
      ],
      "metadata": {
        "id": "PJsTtUbD5SsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "SELECT *\n",
        "  FROM `chocolate_ai.customer_marketing_profile`\n",
        " WHERE customer_profile_data        IS NOT NULL\n",
        "   AND data_beans_profile_data      IS NOT NULL\n",
        "   AND generated_marketing_insights IS NOT NULL\n",
        "   AND customer_text_summary        IS NOT NULL;"
      ],
      "metadata": {
        "id": "DHUip1kW0J6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get some customer process (you can adjust the limit clause)"
      ],
      "metadata": {
        "id": "zKEZCDMH9XS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the customers (if there are not any you can remove some from the chocolate_ai.customer_hyper_personalized_email table)\n",
        "customer_list = []\n",
        "\n",
        "sql = \"\"\"WITH data AS (\n",
        "  SELECT customer_marketing_profile.customer_id,\n",
        "         customer_marketing_profile.customer_profile_data,\n",
        "         customer_marketing_profile.data_beans_profile_data,\n",
        "         customer_marketing_profile.generated_marketing_insights,\n",
        "         customer_marketing_profile.customer_text_summary,\n",
        "        JSON_VALUE(JSON_EXTRACT_ARRAY(data_beans_profile_data.top_3_favorite_menu_items,'$')[0]) as top_1_favorite_menu_item_id,\n",
        "        JSON_VALUE(JSON_EXTRACT_ARRAY(data_beans_profile_data.top_3_favorite_menu_items,'$')[1]) as top_2_favorite_menu_item_id,\n",
        "        JSON_VALUE(JSON_EXTRACT_ARRAY(data_beans_profile_data.top_3_favorite_menu_items,'$')[2]) as top_3_favorite_menu_item_id,\n",
        "    FROM `chocolate_ai.customer_marketing_profile` AS customer_marketing_profile\n",
        "  WHERE customer_profile_data        IS NOT NULL\n",
        "    AND data_beans_profile_data      IS NOT NULL\n",
        "    AND generated_marketing_insights IS NOT NULL\n",
        "    AND customer_text_summary        IS NOT NULL\n",
        "    AND NOT EXISTS (SELECT 1 FROM `chocolate_ai.customer_hyper_personalized_email` AS child where child.customer_id = customer_marketing_profile.customer_id)\n",
        "  ORDER BY customer_id\n",
        "  LIMIT 2\n",
        ")\n",
        "SELECT customer_id,\n",
        "       customer_profile_data,\n",
        "       data_beans_profile_data,\n",
        "       generated_marketing_insights,\n",
        "       customer_text_summary,\n",
        "       CONCAT(menu_1.item_name,':',menu_1.llm_item_description) AS top_1_favorite_menu_item_name,\n",
        "       CONCAT(menu_2.item_name,':',menu_1.llm_item_description) AS top_2_favorite_menu_item_name,\n",
        "       CONCAT(menu_3.item_name,':',menu_1.llm_item_description) AS top_3_favorite_menu_item_name,\n",
        "  FROM data\n",
        "       INNER JOIN `chocolate_ai.menu` AS menu_1\n",
        "               ON CAST(data.top_1_favorite_menu_item_id AS INT64) = menu_1.menu_id\n",
        "       INNER JOIN `chocolate_ai.menu` AS menu_2\n",
        "               ON CAST(data.top_2_favorite_menu_item_id AS INT64) = menu_2.menu_id\n",
        "       INNER JOIN `chocolate_ai.menu` AS menu_3\n",
        "               ON CAST(data.top_3_favorite_menu_item_id AS INT64) = menu_3.menu_id\n",
        "\"\"\"\n",
        "\n",
        "df_process = RunQuery(sql)\n",
        "\n",
        "for row in df_process.itertuples():\n",
        "  customer_dict = {\n",
        "    \"customer_id\" : row.customer_id,\n",
        "    \"customer_profile_data\" :row.customer_profile_data,\n",
        "    \"data_beans_profile_data\" : row.data_beans_profile_data,\n",
        "    \"generated_marketing_insights\" : row.generated_marketing_insights,\n",
        "    \"customer_text_summary\" : row.customer_text_summary,\n",
        "    \"top_1_favorite_menu_item_name\" : row.top_1_favorite_menu_item_name,\n",
        "    \"top_2_favorite_menu_item_name\" : row.top_2_favorite_menu_item_name,\n",
        "    \"top_3_favorite_menu_item_name\" : row.top_3_favorite_menu_item_name\n",
        "  }\n",
        "  print(f\"Customer: {customer_dict}\")\n",
        "  customer_list.append(customer_dict)\n",
        "\n",
        "# Just the Ids so I can query\n",
        "customer_id_list = ([customer['customer_id'] for customer in customer_list])\n",
        "customer_id_list_str = (', '.join(map(str, customer_id_list)))"
      ],
      "metadata": {
        "id": "x3NYyJuT9TGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and run the LLM Marketing Prompt"
      ],
      "metadata": {
        "id": "TqCpfi1P9KtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each customer, generate the marketing prompt and run against Gemini\n",
        "\n",
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"customer_id\" : 0,\n",
        "#    \"email_subject\" : \"text\",\n",
        "#    \"marketing_text\" : \"text\",\n",
        "#    \"explanation\" : \"text\"\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"customer_id\",\n",
        "    \"email_subject\",\n",
        "    \"marketing_text\",\n",
        "    \"explanation\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"customer_id\": {\n",
        "      \"type\": \"integer\",\n",
        "      \"format\": \"int64\"\n",
        "    },\n",
        "    \"email_subject\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"marketing_text\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"explanation\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "for customer_dict in customer_list:\n",
        "  print(f\"Customer id: {customer_dict['customer_id']}\")\n",
        "  retry = 0\n",
        "  success = False\n",
        "  while not success:\n",
        "    try:\n",
        "      prompt = f\"\"\"You are a marketing expert and work at Chocolate A.I. a coffee truck company.\n",
        "      You need to send out a hyper-personalized email to a customer.\n",
        "      We to targeting their top favorite menu item(s) to be included in the email.\n",
        "      Explain your reasoning and place that in the explanation field.\n",
        "      Generate a marketing email for customer {customer_dict['customer_id']} using the below customer profile data.\n",
        "        customer_profile_data: {customer_dict['customer_profile_data']}\n",
        "        data_beans_profile_data: {customer_dict['data_beans_profile_data']}\n",
        "        generated_marketing_insights: {customer_dict['generated_marketing_insights']}\n",
        "        customer_text_summary: {customer_dict['customer_text_summary']}\n",
        "        top_1_favorite_menu_item_name: {customer_dict['top_1_favorite_menu_item_name']}\n",
        "        top_2_favorite_menu_item_name: {customer_dict['top_2_favorite_menu_item_name']}\n",
        "        top_3_favorite_menu_item_name: {customer_dict['top_3_favorite_menu_item_name']}\n",
        "        \"\"\"\n",
        "\n",
        "      print(prompt)\n",
        "      llm_result = GeminiLLM(prompt,response_schema=response_schema)\n",
        "      print(llm_result)\n",
        "      json_result = json.loads(llm_result)\n",
        "      result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
        "      #json_text = json_result['marketing_text'].replace(\"'\",\"\\'\")\n",
        "\n",
        "      # Save to database\n",
        "      try:\n",
        "\n",
        "        sql=f\"\"\"INSERT INTO `chocolate_ai.customer_hyper_personalized_email`\n",
        "                            (customer_id, llm_marketing_prompt, llm_marketing_prompt_response_json, llm_marketing_prompt_response_text)\n",
        "                    VALUES ({customer_dict['customer_id']}, \\\"\\\"\\\"{prompt}\\\"\\\"\\\", JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\\\"\\\"\\\"{json_result['marketing_text']}\\\"\\\"\\\")\"\"\"\n",
        "        # print(sql)\n",
        "        RunQuery(sql)\n",
        "\n",
        "        # Jump out of loop\n",
        "        customer_dict['marketing_text'] = json_result['marketing_text']\n",
        "        customer_dict['email_subject'] = json_result['email_subject']\n",
        "        success = True\n",
        "\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "        print(f\"LLM Marketing Prompt [Success] for Customer {customer_dict['customer_id']}\")\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "      except Exception as e:\n",
        "        retry += 1\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "        print(f\"LLM Marketing Prompt [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      retry += 1\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"LLM Marketing Prompt [Error] for Customer {customer_dict['customer_id']}: {e}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    if retry > 5:\n",
        "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "      print(f\"LLM Marketing Prompt [Retry Limit Reached - Skipping] for Customer {customer_dict['customer_id']}\")\n",
        "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "      break # Skip this customer"
      ],
      "metadata": {
        "id": "mx8rLbqJ95d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, llm_marketing_prompt, llm_marketing_prompt_response_json, llm_marketing_prompt_response_text\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "Xj5NUbf_HoyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an image prompt and enhance it by running it through Gemini\n"
      ],
      "metadata": {
        "id": "aqiUIjPCQPux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each customer, generate an improved image prompt using Gemini\n",
        "\n",
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"customer_id\" : 0,\n",
        "#    \"image_prompt\" : \"text\"\n",
        "#    \"explanation\" : \"text\"\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"customer_id\",\n",
        "    \"image_prompt\",\n",
        "    \"explanation\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"customer_id\": {\n",
        "      \"type\": \"integer\",\n",
        "      \"format\": \"int64\"\n",
        "    },\n",
        "    \"image_prompt\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"explanation\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "for customer_dict in customer_list:\n",
        "  print(f\"Customer id: {customer_dict['customer_id']}\")\n",
        "  retry = 0\n",
        "  success = False\n",
        "  while not success:\n",
        "    try:\n",
        "      prompt = f\"\"\"You are a marketing expert and work at Chocolate A.I. a coffee truck company.\n",
        "      You need to send out a hyper-personalized email to a customer.\n",
        "      Generate a LLM Prompt to generate a marketing image based upon the customer's profile and the marketing message we are sending in the email.\n",
        "      We are a coffee truck company called Chocolate A.I..\n",
        "      We want the image to be specific to this customer and their interests.\n",
        "      Think creatively and use the customer's interests to create a unique image.\n",
        "      This is important to show something about their interests, hobbies, sports, etc.\n",
        "      Do not include any names of professional sports teams since they are copyrighted.\n",
        "      Make sure you state the image should be photo realistic.\n",
        "      Avoid and copyrighted names such as sporting teams names.\n",
        "      Avoid mentioning any celebrity names or specific people.\n",
        "      Do not include references to kids or children in the image prompt.\n",
        "      Only audits can be rendered by the image process.\n",
        "      This this through step by step.\n",
        "      Double check for kids, children, or copyrighted sports teams names.\n",
        "\n",
        "      Customer's profile:\n",
        "        customer_profile_data: {customer_dict['customer_profile_data']}\n",
        "        data_beans_profile_data: {customer_dict['data_beans_profile_data']}\n",
        "        generated_marketing_insights: {customer_dict['generated_marketing_insights']}\n",
        "        customer_text_summary: {customer_dict['customer_text_summary']}\n",
        "        top_1_favorite_menu_item_name: {customer_dict['top_1_favorite_menu_item_name']}\n",
        "        top_2_favorite_menu_item_name: {customer_dict['top_2_favorite_menu_item_name']}\n",
        "        top_3_favorite_menu_item_name: {customer_dict['top_3_favorite_menu_item_name']}\n",
        "\n",
        "      Marketing Message:\n",
        "       {customer_dict['marketing_text']}\n",
        "        \"\"\"\n",
        "\n",
        "      print(prompt)\n",
        "      llm_result = GeminiLLM(prompt,response_schema=response_schema)\n",
        "      print(llm_result)\n",
        "      json_result = json.loads(llm_result)\n",
        "      result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
        "\n",
        "      # Save to database\n",
        "      try:\n",
        "        sql=f\"\"\"UPDATE `chocolate_ai.customer_hyper_personalized_email`\n",
        "                   SET llm_orginial_image_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
        "                       llm_orginial_image_prompt_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
        "                       llm_orginial_image_prompt_response_text = \\\"\\\"\\\"{json_result['image_prompt']}\\\"\\\"\\\",\n",
        "                       llm_improved_image_prompt = \\\"\\\"\\\"{json_result['image_prompt']}\\\"\\\"\\\"\n",
        "                 WHERE customer_id = {customer_dict['customer_id']}\"\"\"\n",
        "\n",
        "        #print(sql)\n",
        "        RunQuery(sql)\n",
        "\n",
        "        # Jump out of loop\n",
        "        customer_dict['image_prompt'] = json_result['image_prompt']\n",
        "        customer_dict['image_explanation'] = json_result['explanation']\n",
        "        success = True\n",
        "\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "        print(f\"LLM Image Prompt [Success] for Customer {customer_dict['customer_id']}\")\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "      except Exception as e:\n",
        "        retry += 1\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "        print(f\"LLM Image Prompt [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "        print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      retry += 1\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"LLM Image Prompt [Error] for Customer {customer_dict['customer_id']}: {e}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    if retry > 5:\n",
        "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "      print(f\"LLM Image Prompt [Retry Limit Reached - Skipping] for Customer {customer_dict['customer_id']}\")\n",
        "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "      break # Skip this customer"
      ],
      "metadata": {
        "id": "yWN__E_hQPu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To view the bucket\n",
        "print(f\"https://console.cloud.google.com/storage/browser/{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email\")"
      ],
      "metadata": {
        "id": "CrbbG_0ddboW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, llm_orginial_image_prompt, llm_orginial_image_prompt_response_json, llm_orginial_image_prompt_response_text, llm_improved_image_prompt\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "nJ7hDwU8QPu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Call Imagen3 with the updated prompt\n"
      ],
      "metadata": {
        "id": "0o5gCL_AWqBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each customer, generate the image using Imagen3\n",
        "for customer_dict in customer_list:\n",
        "  print(f\"Customer id: {customer_dict['customer_id']}\")\n",
        "  try:\n",
        "    image_prompt = customer_dict['image_prompt']\n",
        "    print(f\"Image Prompt: {image_prompt}\")\n",
        "    print(f\"Image Prompt Explanation: {customer_dict['image_explanation']}\")\n",
        "    filename = ImageGen(customer_dict['image_prompt'])\n",
        "\n",
        "    img = Image.open(filename)\n",
        "    img.thumbnail([500,500]) # width, height\n",
        "    IPython.display.display(img)\n",
        "\n",
        "    # Save image to GCS\n",
        "    dest_filename = f\"email_campaign_{customer_dict['customer_id']}.png\"\n",
        "    copy_file_to_gcs(filename, storage_account, f\"chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}/{dest_filename}\")\n",
        "    customer_dict['gcs_filename'] = f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}/{dest_filename}\"\n",
        "    customer_dict['html_filename'] = f\"https://storage.cloud.google.com/{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}/{dest_filename}\"\n",
        "\n",
        "    # Update table in BigQuery\n",
        "    try:\n",
        "      sql=f\"\"\"UPDATE `chocolate_ai.customer_hyper_personalized_email`\n",
        "                  SET image_gcs_filename = '{customer_dict['gcs_filename']}',\n",
        "                      image_http_url = '{customer_dict['html_filename']}',\n",
        "                      image_generated = TRUE\n",
        "                WHERE customer_id = {customer_dict['customer_id']}\"\"\"\n",
        "\n",
        "      #print(sql)\n",
        "      RunQuery(sql)\n",
        "      customer_dict['image_filename'] = filename\n",
        "\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Imagen3 [Success] for Customer {customer_dict['customer_id']}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      retry += 1\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Imagen3 [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "    print(f\"Imagen3 [Error] for Customer {customer_dict['customer_id']}: {e}\")\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "GGgdgKdwWqBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, image_gcs_filename, image_http_url, image_generated\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "SGhMT7ohDPcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify the Generated Image with Gemini Vision"
      ],
      "metadata": {
        "id": "OfwG_ykdCypl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the generate image is correct\n",
        "\n",
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"customer_id\" : 0,\n",
        "#    \"image_verified\" : true\n",
        "#    \"explanation\" : \"text\"\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"customer_id\",\n",
        "    \"image_verified\",\n",
        "    \"explanation\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"customer_id\": {\n",
        "      \"type\": \"integer\",\n",
        "      \"format\": \"int64\"\n",
        "    },\n",
        "    \"image_verified\": {\n",
        "      \"type\": \"boolean\"\n",
        "    },\n",
        "    \"explanation\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "json_schema = '{ \"image_verified\" : true, \"explanation\" : \"text\" }'\n",
        "\n",
        "for customer_dict in customer_list:\n",
        "  print(f\"Customer id: {customer_dict['customer_id']}\")\n",
        "  try:\n",
        "    image_prompt = customer_dict['image_prompt']\n",
        "    print(f\"Image Prompt: {image_prompt}\")\n",
        "    print(f\"Image Prompt Explanation: {customer_dict['image_explanation']}\")\n",
        "    filename = customer_dict['image_filename']\n",
        "\n",
        "    prompt = f\"\"\"I need you to verify that the below image meets the following criteria:\n",
        "    <ImagePrompt>\n",
        "    {customer_dict['image_prompt']}\n",
        "    </ImagePrompt>\n",
        "    <ImageExplanation>\n",
        "    {customer_dict['image_explanation']}\n",
        "    </ImageExplanation>\n",
        "    \"\"\"\n",
        "\n",
        "    print(prompt)\n",
        "    imageBase64 = convert_png_to_base64(filename)\n",
        "    llm_result = GeminiLLM_VerifyImage(prompt, imageBase64, response_schema=response_schema)\n",
        "    print(llm_result)\n",
        "    json_result = json.loads(llm_result)\n",
        "    result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
        "\n",
        "\n",
        "    # Update table in BigQuery\n",
        "    try:\n",
        "      sql=f\"\"\"UPDATE `chocolate_ai.customer_hyper_personalized_email`\n",
        "                  SET llm_verify_image_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
        "                      llm_verify_image_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
        "                      llm_verify_image_text = \\\"\\\"\\\"{json_result['explanation']}\\\"\\\"\\\",\n",
        "                      image_verified = {json_result['image_verified']}\n",
        "                WHERE customer_id = {customer_dict['customer_id']}\"\"\"\n",
        "\n",
        "      #print(sql)\n",
        "      RunQuery(sql)\n",
        "\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Imagen3 Verification [Success] for Customer {customer_dict['customer_id']}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      retry += 1\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Imagen3 Verification [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "    print(f\"Imagen3 Verification [Error] for Customer {customer_dict['customer_id']}: {e}\")\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "V-_J7-7Y-S5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, llm_verify_image_prompt, llm_verify_image_response_json, llm_verify_image_text, image_verified\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "c0H1cwl2CJdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Translate the Marketing Message to another language"
      ],
      "metadata": {
        "id": "OabA8ZAhC5IX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate the marketing text into another language (we will randomly pick on)\n",
        "\n",
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"customer_id\" : 0,\n",
        "#    \"translated_text\" : \"text\"\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"customer_id\",\n",
        "    \"translated_text\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"customer_id\": {\n",
        "      \"type\": \"integer\",\n",
        "      \"format\": \"int64\"\n",
        "    },\n",
        "    \"translated_text\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "for customer_dict in customer_list:\n",
        "  # Pick an random language from the list\n",
        "  random_language = random.randint(0,len(gemini_languages)-1)\n",
        "  print(f\"Random Language: {gemini_languages[random_language]}\")\n",
        "  print(f\"Customer id: {customer_dict['customer_id']}\")\n",
        "  customer_dict['translation_language'] = gemini_languages[random_language]\n",
        "  try:\n",
        "\n",
        "    prompt = f\"\"\"You are an expert translator for the following language {gemini_languages[random_language]}.\n",
        "    Translate the following text from English to {gemini_languages[random_language]}:\n",
        "    <Text>\n",
        "    {customer_dict['marketing_text']}\n",
        "    </Text>\n",
        "    \"\"\"\n",
        "\n",
        "    print(prompt)\n",
        "    llm_result = GeminiLLM(prompt, response_schema=response_schema)\n",
        "    print(llm_result)\n",
        "    json_result = json.loads(llm_result)\n",
        "    result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
        "\n",
        "    # Update table in BigQuery\n",
        "    try:\n",
        "      sql=f\"\"\"UPDATE `chocolate_ai.customer_hyper_personalized_email`\n",
        "                  SET llm_translation_language_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
        "                      llm_translation_language_prompt_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
        "                      llm_translation_language_prompt_response_text = \\\"\\\"\\\"{json_result['translated_text']}\\\"\\\"\\\"\n",
        "                WHERE customer_id = {customer_dict['customer_id']}\"\"\"\n",
        "\n",
        "      #print(sql)\n",
        "      RunQuery(sql)\n",
        "      customer_dict['translated_text'] = json_result['translated_text']\n",
        "\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Translation [Success] for Customer {customer_dict['customer_id']}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      retry += 1\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Translation [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "    print(f\"Translation [Error] for Customer {customer_dict['customer_id']}: {e}\")\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "1xYdA9VKDIQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, llm_translation_language_prompt, llm_translation_language_prompt_response_json, llm_translation_language_prompt_response_text\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "_7QtxRWnP0Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify the Transalation"
      ],
      "metadata": {
        "id": "lrS2IH6VC9l-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the translation is correct\n",
        "\n",
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"customer_id\" : 0,\n",
        "#    \"translation_verified\" : true\n",
        "#    \"explanation\" : \"text\"\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"customer_id\",\n",
        "    \"translation_verified\",\n",
        "    \"explanation\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"customer_id\": {\n",
        "      \"type\": \"integer\",\n",
        "      \"format\": \"int64\"\n",
        "    },\n",
        "    \"translation_verified\": {\n",
        "      \"type\": \"boolean\"\n",
        "    },\n",
        "    \"explanation\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "for customer_dict in customer_list:\n",
        "  print(f\"Customer id: {customer_dict['customer_id']}\")\n",
        "  try:\n",
        "    prompt = f\"\"\"I need you to verify that the below text is in the langugage of \"{customer_dict['translation_language']}\".\n",
        "    It was originially in English, so make sure it is not still English.\n",
        "    <Text>\n",
        "    {customer_dict['translated_text']}\n",
        "    </Text>\n",
        "    \"\"\"\n",
        "\n",
        "    print(prompt)\n",
        "    llm_result = GeminiLLM(prompt, response_schema=response_schema)\n",
        "    print(llm_result)\n",
        "    json_result = json.loads(llm_result)\n",
        "    result_escaped_quotes = llm_result.replace(\"\\\\\",\"\\\\\\\\\").replace(\"'\",\"\\'\")\n",
        "\n",
        "    # Update table in BigQuery\n",
        "    try:\n",
        "      sql=f\"\"\"UPDATE `chocolate_ai.customer_hyper_personalized_email`\n",
        "                  SET llm_validate_translation_prompt = \\\"\\\"\\\"{prompt}\\\"\\\"\\\",\n",
        "                      llm_validate_translation_prompt_response_json = JSON\\\"\\\"\\\"{result_escaped_quotes}\\\"\\\"\\\",\n",
        "                      llm_validate_translation_prompt_response_text = \\\"\\\"\\\"{json_result['explanation']}\\\"\\\"\\\",\n",
        "                      translation_verified = {json_result['translation_verified']}\n",
        "                WHERE customer_id = {customer_dict['customer_id']}\"\"\"\n",
        "\n",
        "      #print(sql)\n",
        "      RunQuery(sql)\n",
        "\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Translation Verification [Success] for Customer {customer_dict['customer_id']}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "    except Exception as e:\n",
        "      retry += 1\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "      print(f\"Translation Verification [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "      print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "    print(f\"Translation Verification [Error] for Customer {customer_dict['customer_id']}: {e}\")\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "I1p7flicDItv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, llm_validate_translation_prompt, llm_validate_translation_prompt_response_json, llm_validate_translation_prompt_response_text, translation_verified\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "dNQoVMarRGxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the HTML and Save"
      ],
      "metadata": {
        "id": "5sCUluQyDB6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html_template = \"\"\"<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "  <title>Coffee Campaign</title>\n",
        "  <style>\n",
        "    body {\n",
        "      font-family: 'Helvetica Neue', sans-serif;\n",
        "    }\n",
        "    .email-campaign {\n",
        "      background-color: #EDF2F9;\n",
        "      padding: 20px;\n",
        "      margin-bottom: 20px;\n",
        "      border-bottom: 2px solid #ddd;\n",
        "    }\n",
        "    h3 {\n",
        "      font-size: 16px;\n",
        "      margin-bottom: 10px;\n",
        "      color: #333;\n",
        "    }\n",
        "    p {\n",
        "      font-size: 14px;\n",
        "      line-height: 1.5;\n",
        "      color: #555;\n",
        "    }\n",
        "  </style>\n",
        "</head>\n",
        "<body>\n",
        "  <div class=\"email-campaign\">\n",
        "    <h3>Email Campaign (English)</h3>\n",
        "    <p style=\"font-weight: bold;\">Subject: ##email_subject##</p>\n",
        "    <p>##marketing_text##</p>\n",
        "  </div>\n",
        "  <div>\n",
        "    <img src=\"##html_filename##\" width=\"500\" height=\"500\" alt=\"Item Image\">\n",
        "  </div>\n",
        "\n",
        "  <hr/>\n",
        "\n",
        "  <div class=\"email-campaign\">\n",
        "    <h3>Email Campaign (##translation_language##)</h3>\n",
        "    <p>##translated_text##</p>\n",
        "  </div>\n",
        "  <div>\n",
        "    <img src=\"##html_filename##\" width=\"500\" height=\"500\" alt=\"Item Image\">\n",
        "  </div>\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xT1UZX2rDJNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create HTML using the Template\n",
        "\n",
        "for customer_dict in customer_list:\n",
        "  if 'html_filename' not in customer_dict:\n",
        "    # Error generating image\n",
        "    print(\"Error: 'html_filename' not in customer_dict\")\n",
        "    continue\n",
        "\n",
        "  if 'translated_text' not in customer_dict:\n",
        "    # Error generating translation\n",
        "    print(\"Error: 'translated_text' not in customer_dict\")\n",
        "    continue\n",
        "\n",
        "  # Replace the placeholders with the actual values\n",
        "  html = html_template \\\n",
        "    .replace(\"##email_subject##\", customer_dict['email_subject']) \\\n",
        "    .replace(\"##marketing_text##\", customer_dict['marketing_text']) \\\n",
        "    .replace(\"##translation_language##\", customer_dict['translation_language']) \\\n",
        "    .replace(\"##translated_text##\", customer_dict['translated_text']) \\\n",
        "    .replace(\"##html_filename##\", customer_dict['html_filename'])\n",
        "\n",
        "  filename = f\"email_campaign_{customer_dict['customer_id']}.html\"\n",
        "\n",
        "  # Save the HTML to a file\n",
        "  with open(filename, \"w\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "  copy_file_to_gcs(filename, storage_account,f\"chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}/\" + filename)\n",
        "\n",
        "  # Update table in BigQuery\n",
        "  try:\n",
        "    html_gcs_filename = f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}/{filename}\"\n",
        "    html_http_url = f\"https://storage.cloud.google.com/{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}/{filename}\"\n",
        "\n",
        "    sql=f\"\"\"UPDATE `chocolate_ai.customer_hyper_personalized_email`\n",
        "                SET html_gcs_filename = '{html_gcs_filename}',\n",
        "                    html_http_url = '{html_http_url}',\n",
        "                    html_generated = TRUE\n",
        "              WHERE customer_id = {customer_dict['customer_id']}\"\"\"\n",
        "\n",
        "    #print(sql)\n",
        "    RunQuery(sql)\n",
        "\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "    print(f\"HTML Generation [Success] for Customer {customer_dict['customer_id']}\")\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "\n",
        "  except Exception as e:\n",
        "    retry += 1\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n",
        "    print(f\"HTML Generation [SQL Error] for Customer {customer_dict['customer_id']}: {sql}\")\n",
        "    print(\"---------------------------------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "id": "I7ApKaWhSdHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To view the bucket\n",
        "print(f\"https://console.cloud.google.com/storage/browser/{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Hyper-Personalized-Email/email-{formatted_date}\")"
      ],
      "metadata": {
        "id": "eAPgeLTndZTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View Results\n",
        "sql=f\"\"\"SELECT customer_id, html_gcs_filename, html_http_url, html_generated\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "VThvmO_SZmF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = f\"email_campaign_{customer_list[0]['customer_id']}.html\"\n",
        "IPython.display.HTML(filename=filename)"
      ],
      "metadata": {
        "id": "WT3u1L_aVayT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = f\"email_campaign_{customer_list[1]['customer_id']}.html\"\n",
        "IPython.display.HTML(filename=filename)"
      ],
      "metadata": {
        "id": "XcRVFkNIXNT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View all results"
      ],
      "metadata": {
        "id": "FfLXgbircpZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View All Results\n",
        "sql=f\"\"\"SELECT *\n",
        "          FROM `chocolate_ai.customer_hyper_personalized_email`\n",
        "         WHERE customer_id IN ({customer_id_list_str})\"\"\"\n",
        "\n",
        "print(sql)\n",
        "df_process = RunQuery(sql)\n",
        "df_process.head()"
      ],
      "metadata": {
        "id": "31W7KOUzZs4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IxhtRRrvR-"
      },
      "source": [
        "### Clean Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lF2Z7skFbvf"
      },
      "outputs": [],
      "source": [
        "# Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQ2BPisXDA0"
      },
      "source": [
        "### Reference Links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTY6xJdZ3ul8"
      },
      "source": [
        "- [Imagen3](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/image-generation)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "JbOjdSP1kN9T",
        "vOFTk6sj1YIV",
        "bI-KJELZ1jgt",
        "EYRHDPdVKBzd",
        "zKEZCDMH9XS7",
        "TqCpfi1P9KtL",
        "0o5gCL_AWqBQ",
        "OabA8ZAhC5IX",
        "lrS2IH6VC9l-",
        "ASQ2BPisXDA0"
      ],
      "name": "DB-GMA-Campaign-Assets-Hyper-Personalized-Email.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}