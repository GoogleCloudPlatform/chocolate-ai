{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### To Do / License\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l85J9wppHuh3"
      },
      "source": [
        "- Create a Marketing campaign Video idea\n",
        "- Pass a the Video to Gemini and ask it to extract Shorts for YouTube, X, TikTok, etc.\n",
        "- Gemini should return the timestamps of the shorts\n",
        "  - Gemini needs to explain its reasoning\n",
        "- Split the video into shorts (in Python?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```\n",
        "\n",
        "Author: Adam Paternostro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX"
      },
      "outputs": [],
      "source": [
        "# To read/write to/from Kafka\n",
        "import sys\n",
        "\n",
        "# https://pypi.org/project/moviepy/\n",
        "!{sys.executable} -m pip install moviepy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df85Okng5iMX"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### Helper Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gemini LLM (Pro 1.0 , Pro 1.5)"
      ],
      "metadata": {
        "id": "-xPgu3MncKSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GeminiLLM(prompt, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": {\n",
        "          \"text\": prompt\n",
        "      },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ],
      "metadata": {
        "id": "IJl_rUxbcMdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gemini LLM - Multimodal"
      ],
      "metadata": {
        "id": "4brvnJOIlXOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GeminiLLM_Multimodal(multimodal_prompt_list, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": multimodal_prompt_list\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ],
      "metadata": {
        "id": "UvhIiqqkcPur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download GCS file"
      ],
      "metadata": {
        "id": "eqIt4BcJlhnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_from_gcs(filename, gcs_storage_bucket, gcs_storage_path):\n",
        "  # prompt: Write python code to download a blob from a gcs bucket.  do not use the requests method\n",
        "\n",
        "  from google.cloud import storage\n",
        "\n",
        "  # The ID of your GCS object\n",
        "  object_name = gcs_storage_path + filename\n",
        "\n",
        "  # The path to which the file should be downloaded\n",
        "  destination_file_name = filename\n",
        "\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  bucket = storage_client.bucket(gcs_storage_bucket)\n",
        "\n",
        "  # Construct a client side representation of a blob.\n",
        "  # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
        "  # any content from Google Cloud Storage. As we don't need additional data,\n",
        "  # using `Bucket.blob` is preferred here.\n",
        "  blob = bucket.blob(object_name)\n",
        "  blob.download_to_filename(destination_file_name)\n",
        "\n",
        "  print(\n",
        "      \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
        "          object_name, gcs_storage_bucket, destination_file_name\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "YGNfJcHZkqyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Copy file to GCS"
      ],
      "metadata": {
        "id": "IZibXtjkllRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This was generated by GenAI\n",
        "\n",
        "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
        "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
        "\n",
        "  Args:\n",
        "      local_file_path: The full path to the local file.\n",
        "      bucket_name: The name of the GCS bucket to upload to.\n",
        "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  import os\n",
        "  from google.cloud import storage\n",
        "\n",
        "  # Ensure the file exists locally\n",
        "  if not os.path.exists(local_file_path):\n",
        "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
        "\n",
        "  # Create a storage client\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  # Get a reference to the bucket\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "  # Create a blob object with the desired destination path\n",
        "  blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "  # Upload the file from the local filesystem\n",
        "  content_type = \"\"\n",
        "  if local_file_path.endswith(\".html\"):\n",
        "    content_type = \"text/html; charset=utf-8\"\n",
        "\n",
        "  if local_file_path.endswith(\".json\"):\n",
        "    content_type = \"application/json; charset=utf-8\"\n",
        "\n",
        "  if content_type == \"\":\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "  else:\n",
        "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
        "\n",
        "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\")"
      ],
      "metadata": {
        "id": "Hjyf9J8Bk8h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text-to-Speech"
      ],
      "metadata": {
        "id": "O-RP_lUAs_8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TextToSpeechLanguageList(language_code):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token,\n",
        "      \"x-goog-user-project\" : project\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/text-to-speech/docs/reference/rest/v1/voices/list\n",
        "  url = f\"https://texttospeech.googleapis.com/v1/voices?languageCode={language_code}\"\n",
        "\n",
        "  response = requests.get(url, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return response.text\n",
        "  else:\n",
        "    error = f\"Error with language_code:'{language_code}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ],
      "metadata": {
        "id": "8jTIYEkVtBLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TextToSpeech(local_filename, text, language_code, language_code_name, ssml_gender, speaking_rate = 1):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token,\n",
        "      \"x-goog-user-project\" : project\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/text-to-speech/docs/reference/rest/v1/text/synthesize\n",
        "  url = f\"https://texttospeech.googleapis.com/v1/text:synthesize\"\n",
        "\n",
        "  payload = {\n",
        "   \"input\": {\n",
        "      \"text\": text\n",
        "   },\n",
        "   \"voice\": {\n",
        "      \"languageCode\": language_code,\n",
        "      \"name\": language_code_name,\n",
        "      \"ssmlGender\": ssml_gender # FEMALE | MALE\n",
        "   },\n",
        "   \"audioConfig\": {\n",
        "      \"audioEncoding\": \"MP3\",\n",
        "      \"speakingRate\": speaking_rate,\n",
        "   }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    audio_data = json.loads(response.content)[\"audioContent\"]\n",
        "    audio_data = base64.b64decode(audio_data)\n",
        "    with open(local_filename, \"wb\") as f:\n",
        "      f.write(audio_data)\n",
        "    print(f\"Audio generated OK.\")\n",
        "    return local_filename\n",
        "  else:\n",
        "    error = f\"Error with text:'{text}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ],
      "metadata": {
        "id": "fudhvp8mtBxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MergeVideoAndAudio and ExtractClip"
      ],
      "metadata": {
        "id": "2Vmk1TVJuiRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "def MergeVideoAndAudio(video_filename, audio_filename, output_filename):\n",
        "  # Load the video and audio files\n",
        "  video = VideoFileClip(video_filename)\n",
        "  audio = AudioFileClip(audio_filename)\n",
        "\n",
        "  # Combine the video and audio\n",
        "  final_clip = video.set_audio(audio)\n",
        "\n",
        "  # Save the combined video\n",
        "  final_clip.write_videofile(output_filename)"
      ],
      "metadata": {
        "id": "C9JDeCp4ujPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *\n",
        "\n",
        "def ExtractClip(input_video_path, start_time, end_time):\n",
        "  # Load the video clip\n",
        "  clip = VideoFileClip(input_video_path)\n",
        "\n",
        "  # Extract the desired segment\n",
        "  extracted_clip = clip.subclip(start_time, end_time)\n",
        "\n",
        "  # Save the extracted clip as a new video file\n",
        "  extracted_clip.write_videofile(youtube_extracted_clip_video_filename)"
      ],
      "metadata": {
        "id": "tBABNiHMujht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "rfhk5Jl6FO3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: python to delete a file even if it does not exist\n",
        "\n",
        "def delete_file(filename):\n",
        "  try:\n",
        "    os.remove(filename)\n",
        "    print(f\"File '{filename}' deleted successfully.\")\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File '{filename}' not found.\")"
      ],
      "metadata": {
        "id": "e9GDbcDvFQVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PrettyPrintJson(json_string):\n",
        "  json_object = json.loads(json_string)\n",
        "  json_formatted_str = json.dumps(json_object, indent=2)\n",
        "  #print(json_formatted_str)\n",
        "  return json.dumps(json_object)"
      ],
      "metadata": {
        "id": "a9a_8SEKFTbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: python code to download a pdf from the internet\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_http_file(url, filename):\n",
        "  \"\"\"Downloads a PDF file from a given URL.\n",
        "\n",
        "  Args:\n",
        "      url: The URL of the PDF file to download.\n",
        "      filename: The name to save the downloaded PDF file as.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    with open(filename, 'wb') as f:\n",
        "      f.write(response.content)\n",
        "\n",
        "    print(f\"PDF downloaded successfully to {filename}\")\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"An error occurred while downloading the PDF: {e}\")\n",
        "\n",
        "# Example usage:\n"
      ],
      "metadata": {
        "id": "XWE1mzs_VRG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYRHDPdVKBzd"
      },
      "source": [
        "### Download Existing Ad and Best Pratices for Creating YouTube Shorts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz2lUhuh5iMY"
      },
      "outputs": [],
      "source": [
        "# Download our sample Chocolate A.I. Ad and upload to our project storage account\n",
        "download_from_gcs(\"mocha-magic-video-only-combined.mp4\", \"data-analytics-golden-demo\", \"chocolate-ai/v2/Campaign-Assets-Video-Text2Video/Mocha-Magic/\")\n",
        "copy_file_to_gcs(\"mocha-magic-video-only-combined.mp4\", storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/mocha-magic-video-only-combined.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://blog.google/products/ads-commerce/youtube-shorts-ads-select-lineups-abcds/\n",
        "abcd_url = \"https://services.google.com/fh/files/misc/formarketingshortsabcdsonesheeters.pdf\"\n",
        "abcd_filename = \"formarketingshortsabcdsonesheeters.pdf\"\n",
        "download_http_file(abcd_url, abcd_filename)\n",
        "copy_file_to_gcs(\"formarketingshortsabcdsonesheeters.pdf\", storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/YouTube-Shorts-Best-Practices.pdf\")"
      ],
      "metadata": {
        "id": "pQwtjvJzVK-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://arxiv.org/html/2402.18208v1\n",
        "# Shorts on the Rise: Assessing the Effects of YouTube: Shorts on Long-Form Video Content\n",
        "arxiv_url = \"https://arxiv.org/pdf/2402.18208v1\"\n",
        "arxiv_filename = \"Shorts-on-the-Rise-Assessing-the-Effects-of-YouTube.pdf\"\n",
        "download_http_file(arxiv_url, arxiv_filename)\n",
        "copy_file_to_gcs(arxiv_filename, storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/{arxiv_filename}\")"
      ],
      "metadata": {
        "id": "uHLEQTfMY3RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YouTube Short - Gemini Prompt"
      ],
      "metadata": {
        "id": "4PCGPbpIVb1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"youtube_short_description\" : \"text\",\n",
        "#    \"youtube_short_begin_timestamp\" : \"text\",\n",
        "#    \"youtube_short_end_timestamp\" : \"text\",\n",
        "#    \"youtube_short_explanation\" : \"text\",\n",
        "#    \"youtube_short_voice_over\" : \"text\"\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"youtube_short_description\",\n",
        "    \"youtube_short_begin_timestamp\",\n",
        "    \"youtube_short_end_timestamp\",\n",
        "    \"youtube_short_explanation\",\n",
        "    \"youtube_short_voice_over\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"youtube_short_description\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"youtube_short_begin_timestamp\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"youtube_short_end_timestamp\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"youtube_short_explanation\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"youtube_short_voice_over\": {\n",
        "      \"type\": \"string\"\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "prompt = \"\"\"I need you to watch the video and find the most interesting exciting part for a YouTube short.\n",
        "I attached the file YouTube-Shorts-Best-Practices.pdf which contains the best practices for creating a YouTube short.\n",
        "Incorporate the best practices into the video.\n",
        "This is for a company called \"Chocolate A.I.\" who runs coffee trucks in the UK (London).\n",
        "Select the best 10 to 15 seconds of based upon the YouTube-Shorts-Best-Practices.pdf.\n",
        "Write a 10 to 15 second voice over for the segment.\n",
        "- The voice over shoud be a short, engaging, and memorable.\n",
        "- The voice over should have an introduction and conclusion.\n",
        "\"\"\"\n",
        "\n",
        "multimodal_prompt_list = [\n",
        "    { \"text\": prompt },\n",
        "    { \"fileData\": {  \"mimeType\": \"video/mp4\", \"fileUri\": f\"gs://data-analytics-preview/chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/mocha-magic-video-only-combined.mp4\" } },\n",
        "    { \"fileData\": {  \"mimeType\": \"application/pdf\", \"fileUri\": f\"gs://data-analytics-preview/chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/YouTube-Shorts-Best-Practices.pdf\" } },\n",
        "    { \"fileData\": {  \"mimeType\": \"application/pdf\", \"fileUri\": f\"gs://data-analytics-preview/chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/Shorts-on-the-Rise-Assessing-the-Effects-of-YouTube.pdf\" } }\n",
        "  ]\n",
        "\n",
        "youtube_short_response = GeminiLLM_Multimodal(multimodal_prompt_list, response_schema=response_schema)"
      ],
      "metadata": {
        "id": "uzxW2WR7lygS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_short_dict = json.loads(youtube_short_response)\n",
        "\n",
        "youtube_extracted_clip_video_filename = \"youtube-extract-clip.mp4\"\n",
        "youtube_extracted_clip_audio_filename = \"youtube-extract-clip.mp3\"\n",
        "youtube_short_filename = \"youtube-short.mp4\"\n",
        "\n",
        "print(f\"youtube_short_description: {youtube_short_dict['youtube_short_description']}\")\n",
        "print(f\"youtube_short_begin_timestamp: {youtube_short_dict['youtube_short_begin_timestamp']}\")\n",
        "print(f\"youtube_short_end_timestamp: {youtube_short_dict['youtube_short_end_timestamp']}\")\n",
        "print(f\"youtube_short_explanation: {youtube_short_dict['youtube_short_explanation']}\")\n",
        "print(f\"youtube_short_voice_over: {youtube_short_dict['youtube_short_voice_over']}\")"
      ],
      "metadata": {
        "id": "m9K5eyCdvJfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YouTube Short - Extract the Video Short"
      ],
      "metadata": {
        "id": "ZP_ydCRuVl5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ExtractClip(\"mocha-magic-video-only-combined.mp4\", youtube_short_dict['youtube_short_begin_timestamp'], youtube_short_dict['youtube_short_end_timestamp'])"
      ],
      "metadata": {
        "id": "gmGzxNEum7jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: python to play a mp4 in a jupyter notebook\n",
        "mocha_magic_ad_full_video_mp4 = open(youtube_extracted_clip_video_filename, 'rb').read()\n",
        "mocha_magic_ad_full_video_url = \"data:video/mp4;base64,\" + base64.b64encode(mocha_magic_ad_full_video_mp4).decode()"
      ],
      "metadata": {
        "id": "RD4OmWrjnERR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16:9 aspect ratio\n",
        "HTML(f\"\"\"\n",
        "<p>YouTube Short (no audio)</p>\n",
        "<video width=600 height=337 controls>\n",
        "      <source src=\"{mocha_magic_ad_full_video_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "mGqtZ7fUnJxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YouTube Short - Generate the Audio (Voice Over)"
      ],
      "metadata": {
        "id": "u2GZgiuIVq_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out a list of language code, select one you want\n",
        "response_text = TextToSpeechLanguageList(\"en-gb\")\n",
        "response_json = json.loads(response_text)\n",
        "print (response_json)\n",
        "# print(PrettyPrintJson(response_text))\n",
        "\n",
        "language_code = \"en-gb\"\n",
        "language_code_name = \"en-GB-Standard-B\"\n",
        "ssml_gender = \"MALE\""
      ],
      "metadata": {
        "id": "_vQwcTMTsxrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the text-to-speech for each segment\n",
        "\n",
        "# Output of video files\n",
        "voiceover_prompt = youtube_short_dict['youtube_short_voice_over']\n",
        "print(f\"Generating: {voiceover_prompt}\")\n",
        "# Text-to-Speech\n",
        "TextToSpeech(youtube_extracted_clip_audio_filename, voiceover_prompt, language_code, language_code_name, ssml_gender, 1.15)\n",
        "display(Audio(youtube_extracted_clip_audio_filename, autoplay=True,rate=16000))\n",
        "print()"
      ],
      "metadata": {
        "id": "5yzk0dXfs4-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YouTube Short - Merge Video and Audio for Final Video"
      ],
      "metadata": {
        "id": "j1NUfC5BVxRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MergeVideoAndAudio(youtube_extracted_clip_video_filename,youtube_extracted_clip_audio_filename,youtube_short_filename)"
      ],
      "metadata": {
        "id": "cB55QHAjttA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: python to play a mp4 in a jupyter notebook\n",
        "full_video_mp4 = open(youtube_short_filename, 'rb').read()\n",
        "full_video_url = \"data:video/mp4;base64,\" + base64.b64encode(full_video_mp4).decode()"
      ],
      "metadata": {
        "id": "sykGlyoMuAlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16:9 aspect ratio\n",
        "HTML(f\"\"\"\n",
        "<p>YouTube Short (with Audio)</p>\n",
        "<video width=600 height=337 controls>\n",
        "      <source src=\"{full_video_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "cv1OAmpWuGGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YouTube Short - Upload Artifacts to GCS"
      ],
      "metadata": {
        "id": "mzu3RTyvC_0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copy_file_to_gcs(\"formarketingshortsabcdsonesheeters.pdf\", storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/formarketingshortsabcdsonesheeters.pdf\")\n",
        "copy_file_to_gcs(\"mocha-magic-video-only-combined.mp4\",    storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/mocha-magic-video-only-combined.mp4\")\n",
        "copy_file_to_gcs(youtube_extracted_clip_video_filename,    storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/{youtube_extracted_clip_video_filename}\")\n",
        "copy_file_to_gcs(youtube_extracted_clip_audio_filename,    storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/{youtube_extracted_clip_audio_filename}\")\n",
        "copy_file_to_gcs(youtube_short_filename,                   storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/{youtube_short_filename}\")\n",
        "\n",
        "# Save the prompt so we know how we got this data\n",
        "with open(\"gemini_youtube_short_prompt.txt\", \"w\") as f:\n",
        "  f.write(prompt)\n",
        "copy_file_to_gcs(\"gemini_youtube_short_prompt.txt\", storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/gemini_youtube_short_prompt.txt\")\n",
        "delete_file(\"gemini_youtube_short_prompt.txt\")\n",
        "\n",
        "# Save the output of the prompt\n",
        "with open(\"gemini_youtube_short_prompt_results.txt\", \"w\") as f:\n",
        "  f.write(PrettyPrintJson(json.dumps(youtube_short_dict)))\n",
        "copy_file_to_gcs(\"gemini_youtube_short_prompt_results.txt\", storage_account, f\"chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}/gemini_youtube_short_prompt_results.txt\")\n",
        "delete_file(\"gemini_youtube_short_prompt_results.txt\")\n",
        "\n",
        "# To view the bucket\n",
        "print()\n",
        "print(\"Click here to view the bucket\")\n",
        "print(f\"https://console.cloud.google.com/storage/browser/{storage_account}/chocolate-ai/Campaign-Assets-Video-Create-Shorts/youtube-short-{formatted_date}\")"
      ],
      "metadata": {
        "id": "IaWU5rWRDBvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IxhtRRrvR-"
      },
      "source": [
        "### Clean Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lF2Z7skFbvf"
      },
      "outputs": [],
      "source": [
        "# Placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQ2BPisXDA0"
      },
      "source": [
        "### Reference Links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPlXU4Tv5iMZ"
      },
      "source": [
        "- [Google.com](https://www.google.com)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "JbOjdSP1kN9T",
        "eqIt4BcJlhnk",
        "IZibXtjkllRV",
        "O-RP_lUAs_8v",
        "2Vmk1TVJuiRd",
        "EYRHDPdVKBzd",
        "4PCGPbpIVb1l",
        "ZP_ydCRuVl5c",
        "u2GZgiuIVq_M",
        "j1NUfC5BVxRb",
        "mzu3RTyvC_0J",
        "42IxhtRRrvR-",
        "ASQ2BPisXDA0"
      ],
      "name": "Campaign-Assets-Video-Create-Shorts.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}