{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMsUvoF4BP7Y"
      },
      "source": [
        "### To Do / License"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l85J9wppHuh3"
      },
      "source": [
        "- Create a Marketing campaign Video idea\n",
        "- Need to make sure the idea checks off 75% of the ABCD detector tests\n",
        "- The video will be used for running through the ABCD detector\n",
        "- Generate many 6 second Veo videos\n",
        "- Combine them into a single video\n",
        "- Pass the video to Gemini and ask it to write a script\n",
        "- Pass the script to text to speech\n",
        "- Combine the speech with the video (can we do in Python?  Camtasia)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQgQkbOvj55d"
      },
      "source": [
        "```\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "```\n",
        "\n",
        "Author: Adam Paternostro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65vp54BUFRi"
      },
      "source": [
        "### Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MaWM6H5i6rX"
      },
      "outputs": [],
      "source": [
        "# To read/write to/from Kafka\n",
        "import sys\n",
        "\n",
        "# https://pypi.org/project/moviepy/\n",
        "!{sys.executable} -m pip install moviepy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmyL-Rg4Dr_f"
      },
      "source": [
        "### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOYsEVSXp6IP"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import HTML\n",
        "from IPython.display import Audio\n",
        "from functools import reduce\n",
        "import IPython.display\n",
        "import google.auth\n",
        "import requests\n",
        "import json\n",
        "import uuid\n",
        "import base64\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "import base64\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMlHl3bnkFPZ"
      },
      "outputs": [],
      "source": [
        "# Set these (run this cell to verify the output)\n",
        "\n",
        "bigquery_location = \"us\"\n",
        "region = \"us-central1\"\n",
        "location = \"us-central1\"\n",
        "storage_account = \"data-analytics-preview\"\n",
        "video_number_of_segments = 10\n",
        "video_segment_length = 6\n",
        "video_length_in_seconds = video_number_of_segments * video_segment_length\n",
        "public_storage_storage_account = \"data-analytics-golden-demo\"\n",
        "use_precanned_demo  = True\n",
        "which_precanned_demo = \"precanned_01_mocha_magic_ad_script\"\n",
        "\n",
        "# Get the current date and time\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "# Format the date and time as desired\n",
        "formatted_date = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "# Get some values using gcloud\n",
        "project_id = !(gcloud config get-value project)\n",
        "user = !(gcloud auth list --filter=status:ACTIVE --format=\"value(account)\")\n",
        "\n",
        "if len(project_id) != 1:\n",
        "  raise RuntimeError(f\"project_id is not set: {project_id}\")\n",
        "project_id = project_id[0]\n",
        "\n",
        "if len(user) != 1:\n",
        "  raise RuntimeError(f\"user is not set: {user}\")\n",
        "user = user[0]\n",
        "\n",
        "print(f\"project_id = {project_id}\")\n",
        "print(f\"user = {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ6m_wGrK0YG"
      },
      "source": [
        "### Helper Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbOjdSP1kN9T"
      },
      "source": [
        "#### restAPIHelper\n",
        "Calls the Google Cloud REST API using the current users credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40wlwnY4kM11"
      },
      "outputs": [],
      "source": [
        "def restAPIHelper(url: str, http_verb: str, request_body: str) -> str:\n",
        "  \"\"\"Calls the Google Cloud REST API passing in the current users credentials\"\"\"\n",
        "\n",
        "  import requests\n",
        "  import google.auth\n",
        "  import json\n",
        "\n",
        "  # Get an access token based upon the current user\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "    \"Content-Type\" : \"application/json\",\n",
        "    \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  if http_verb == \"GET\":\n",
        "    response = requests.get(url, headers=headers)\n",
        "  elif http_verb == \"POST\":\n",
        "    response = requests.post(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PUT\":\n",
        "    response = requests.put(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"PATCH\":\n",
        "    response = requests.patch(url, json=request_body, headers=headers)\n",
        "  elif http_verb == \"DELETE\":\n",
        "    response = requests.delete(url, headers=headers)\n",
        "  else:\n",
        "    raise RuntimeError(f\"Unknown HTTP verb: {http_verb}\")\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return json.loads(response.content)\n",
        "    #image_data = json.loads(response.content)[\"predictions\"][0][\"bytesBase64Encoded\"]\n",
        "  else:\n",
        "    error = f\"Error restAPIHelper -> ' Status: '{response.status_code}' Text: '{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gemini LLM (Pro 1.0 , Pro 1.5)"
      ],
      "metadata": {
        "id": "Hh6lubX6VTHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GeminiLLM(prompt, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": {\n",
        "          \"text\": prompt\n",
        "      },\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ],
      "metadata": {
        "id": "KkX3St_QVVJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gemini LLM - Multimodal"
      ],
      "metadata": {
        "id": "5dHoF0tzHlZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GeminiLLM_Multimodal(multimodal_prompt_list, model = \"gemini-1.5-pro-001\", response_schema = None,\n",
        "                 temperature = 1, topP = 1, topK = 32):\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported_models\n",
        "  # model = \"gemini-1.5-pro-001\"\n",
        "  # model = \"gemini-pro\" # This does support topK (but the function is more generic)\n",
        "  # model = \"gemini-1.0-pro\" # This does not support response_schema\n",
        "\n",
        "  llm_response = None\n",
        "  if temperature < 0:\n",
        "    temperature = 0\n",
        "\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request() # required to acess access token\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{location}/publishers/google/models/{model}:generateContent\"\n",
        "\n",
        "  generation_config = {\n",
        "    \"temperature\": temperature,\n",
        "    \"topP\": topP,\n",
        "    \"maxOutputTokens\": 8192,\n",
        "    \"candidateCount\": 1,\n",
        "    \"responseMimeType\": \"application/json\",\n",
        "  }\n",
        "\n",
        "  # Add inthe response schema for when it is provided\n",
        "  if response_schema is not None:\n",
        "    generation_config[\"responseSchema\"] = response_schema\n",
        "\n",
        "  if model == \"gemini-pro\" or model == \"gemini-1.0-pro\" or model == \"gemini-1.0-pro-vision-001\":\n",
        "    generation_config[\"topK\"] = topK\n",
        "\n",
        "  payload = {\n",
        "    \"contents\": {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": multimodal_prompt_list\n",
        "    },\n",
        "    \"generation_config\": {\n",
        "      **generation_config\n",
        "    },\n",
        "    \"safety_settings\": {\n",
        "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    try:\n",
        "      json_response = json.loads(response.content)\n",
        "    except Exception as error:\n",
        "      raise RuntimeError(f\"An error occurred parsing the JSON: {error}\")\n",
        "\n",
        "    if \"candidates\" in json_response:\n",
        "      candidates = json_response[\"candidates\"]\n",
        "      if len(candidates) > 0:\n",
        "        candidate = candidates[0]\n",
        "        if \"content\" in candidate:\n",
        "          content = candidate[\"content\"]\n",
        "          if \"parts\" in content:\n",
        "            parts = content[\"parts\"]\n",
        "            if len(parts):\n",
        "              part = parts[0]\n",
        "              if \"text\" in part:\n",
        "                text = part[\"text\"]\n",
        "                llm_response = text\n",
        "              else:\n",
        "                raise RuntimeError(\"No text in part: {response.content}\")\n",
        "            else:\n",
        "              raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "          else:\n",
        "            raise RuntimeError(\"No parts in content: {response.content}\")\n",
        "        else:\n",
        "          raise RuntimeError(\"No content in candidate: {response.content}\")\n",
        "      else:\n",
        "        raise RuntimeError(\"No candidates: {response.content}\")\n",
        "    else:\n",
        "      raise RuntimeError(\"No candidates: {response.content}\")\n",
        "\n",
        "    # Remove some typically response characters (if asking for a JSON reply)\n",
        "    llm_response = llm_response.replace(\"```json\",\"\")\n",
        "    llm_response = llm_response.replace(\"```\",\"\")\n",
        "    llm_response = llm_response.replace(\"\\n\",\"\")\n",
        "\n",
        "    return llm_response\n",
        "\n",
        "  else:\n",
        "    raise RuntimeError(f\"Error with prompt:'{multimodal_prompt_list[0]}'  Status:'{response.status_code}' Text:'{response.text}'\")"
      ],
      "metadata": {
        "id": "saJMOmA0HcVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Veo Image Generation"
      ],
      "metadata": {
        "id": "wySHopHNei3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VeoVideoGen(prompt, storage_uri):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token\n",
        "  }\n",
        "\n",
        "  model_version = \"veo-001-preview\"\n",
        "\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/image/text-to-live-images#rest\n",
        "  url = f\"https://{location}-aiplatform.googleapis.com/v1/projects/{project}/locations/{location}/publishers/google/models/{model_version}:predictLongRunning\"\n",
        "\n",
        "\n",
        "  payload = {\n",
        "    \"instances\": [\n",
        "      {\n",
        "        \"prompt\": prompt\n",
        "      }\n",
        "    ],\n",
        "    \"parameters\": {\n",
        "      \"storageUri\" : storage_uri\n",
        "    }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    print(f\"Video submitted for processing.\")\n",
        "    return True\n",
        "  else:\n",
        "    error = f\"Error with prompt:'{prompt}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ],
      "metadata": {
        "id": "4WJrd4KQeji1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text to Speech Generation"
      ],
      "metadata": {
        "id": "IT_AtoA3gV4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TextToSpeechLanguageList(language_code):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token,\n",
        "      \"x-goog-user-project\" : project\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/text-to-speech/docs/reference/rest/v1/voices/list\n",
        "  url = f\"https://texttospeech.googleapis.com/v1/voices?languageCode={language_code}\"\n",
        "\n",
        "  response = requests.get(url, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    return response.text\n",
        "  else:\n",
        "    error = f\"Error with language_code:'{language_code}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ],
      "metadata": {
        "id": "dIwlOZ7BgZu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TextToSpeech(local_filename, text, language_code, language_code_name, ssml_gender, speaking_rate = 1):\n",
        "  creds, project = google.auth.default()\n",
        "  auth_req = google.auth.transport.requests.Request()\n",
        "  creds.refresh(auth_req)\n",
        "  access_token=creds.token\n",
        "\n",
        "  headers = {\n",
        "      \"Content-Type\" : \"application/json\",\n",
        "      \"Authorization\" : \"Bearer \" + access_token,\n",
        "      \"x-goog-user-project\" : project\n",
        "  }\n",
        "\n",
        "  # https://cloud.google.com/text-to-speech/docs/reference/rest/v1/text/synthesize\n",
        "  url = f\"https://texttospeech.googleapis.com/v1/text:synthesize\"\n",
        "\n",
        "  payload = {\n",
        "   \"input\": {\n",
        "      \"text\": text\n",
        "   },\n",
        "   \"voice\": {\n",
        "      \"languageCode\": language_code,\n",
        "      \"name\": language_code_name,\n",
        "      \"ssmlGender\": ssml_gender # FEMALE | MALE\n",
        "   },\n",
        "   \"audioConfig\": {\n",
        "      \"audioEncoding\": \"MP3\",\n",
        "      \"speakingRate\": speaking_rate,\n",
        "   }\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    audio_data = json.loads(response.content)[\"audioContent\"]\n",
        "    audio_data = base64.b64decode(audio_data)\n",
        "    with open(local_filename, \"wb\") as f:\n",
        "      f.write(audio_data)\n",
        "    print(f\"Audio generated OK.\")\n",
        "    return local_filename\n",
        "  else:\n",
        "    error = f\"Error with text:'{text}'  Status:'{response.status_code}' Text:'{response.text}'\"\n",
        "    raise RuntimeError(error)"
      ],
      "metadata": {
        "id": "Xh7R560ojLrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Overlay text to speech to video"
      ],
      "metadata": {
        "id": "CWYQfM8BK5Sn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "def MergeVideoAndAudio(video_filename, audio_filename, output_filename):\n",
        "  # Load the video and audio files\n",
        "  video = VideoFileClip(video_filename)\n",
        "  audio = AudioFileClip(audio_filename)\n",
        "\n",
        "  # Combine the video and audio\n",
        "  final_clip = video.set_audio(audio)\n",
        "\n",
        "  # Save the combined video\n",
        "  final_clip.write_videofile(output_filename)"
      ],
      "metadata": {
        "id": "bq7vG0KBK9XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine Videos"
      ],
      "metadata": {
        "id": "0ZcHJOCOxVlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
        "\n",
        "def merge_videos_sorted(folder_path, output_video_name):\n",
        "  \"\"\"\n",
        "  Merges all MP4 video files in the specified folder into a single video,\n",
        "  sorted by file name.\n",
        "\n",
        "  Args:\n",
        "      folder_path: The path to the folder containing the videos.\n",
        "  \"\"\"\n",
        "\n",
        "  video_files = [f for f in os.listdir(folder_path) if f.endswith('.mp4')]\n",
        "  video_files.sort()  # Sort the files by name\n",
        "\n",
        "  clips = [VideoFileClip(os.path.join(folder_path, video)) for video in video_files]\n",
        "\n",
        "  final_clip = concatenate_videoclips(clips)\n",
        "  final_clip.write_videofile(os.path.join(folder_path, output_video_name))"
      ],
      "metadata": {
        "id": "O0NSV7A9xZQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "bNKaaW5ohCpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RunQuery(sql):\n",
        "  import time\n",
        "  from google.cloud import bigquery\n",
        "  client = bigquery.Client()\n",
        "\n",
        "  if (sql.startswith(\"SELECT\") or sql.startswith(\"WITH\")):\n",
        "      df_result = client.query(sql).to_dataframe()\n",
        "      return df_result\n",
        "  else:\n",
        "    job_config = bigquery.QueryJobConfig(priority=bigquery.QueryPriority.INTERACTIVE)\n",
        "    query_job = client.query(sql, job_config=job_config)\n",
        "\n",
        "    # Check on the progress by getting the job's updated state.\n",
        "    query_job = client.get_job(\n",
        "        query_job.job_id, location=query_job.location\n",
        "    )\n",
        "    print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    while query_job.state != \"DONE\":\n",
        "      time.sleep(2)\n",
        "      query_job = client.get_job(\n",
        "          query_job.job_id, location=query_job.location\n",
        "          )\n",
        "      print(\"Job {} is currently in state {} with error result of {}\".format(query_job.job_id, query_job.state, query_job.error_result))\n",
        "\n",
        "    if query_job.error_result == None:\n",
        "      return True\n",
        "    else:\n",
        "      raise Exception(query_job.error_result)"
      ],
      "metadata": {
        "id": "K_Liz2MS2JKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This was generated by GenAI\n",
        "\n",
        "def copy_file_to_gcs(local_file_path, bucket_name, destination_blob_name):\n",
        "  \"\"\"Copies a file from a local drive to a GCS bucket.\n",
        "\n",
        "  Args:\n",
        "      local_file_path: The full path to the local file.\n",
        "      bucket_name: The name of the GCS bucket to upload to.\n",
        "      destination_blob_name: The desired name of the uploaded file in the bucket.\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "\n",
        "  import os\n",
        "  from google.cloud import storage\n",
        "\n",
        "  # Ensure the file exists locally\n",
        "  if not os.path.exists(local_file_path):\n",
        "      raise FileNotFoundError(f\"Local file '{local_file_path}' not found.\")\n",
        "\n",
        "  # Create a storage client\n",
        "  storage_client = storage.Client()\n",
        "\n",
        "  # Get a reference to the bucket\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "  # Create a blob object with the desired destination path\n",
        "  blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "  # Upload the file from the local filesystem\n",
        "  content_type = \"\"\n",
        "  if local_file_path.endswith(\".html\"):\n",
        "    content_type = \"text/html; charset=utf-8\"\n",
        "\n",
        "  if local_file_path.endswith(\".json\"):\n",
        "    content_type = \"application/json; charset=utf-8\"\n",
        "\n",
        "  if content_type == \"\":\n",
        "    blob.upload_from_filename(local_file_path)\n",
        "  else:\n",
        "    blob.upload_from_filename(local_file_path, content_type = content_type)\n",
        "\n",
        "  print(f\"File '{local_file_path}' uploaded to GCS bucket '{bucket_name}' as '{destination_blob_name}.  Content-Type: {content_type}'.\")"
      ],
      "metadata": {
        "id": "1VjvnfpBzN4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_from_gcs(destination_file_name, gcs_storage_bucket, object_name):\n",
        "  # prompt: Write python code to download a blob from a gcs bucket.  do not use the requests method\n",
        "\n",
        "  from google.cloud import storage\n",
        "  storage_client = storage.Client()\n",
        "  bucket = storage_client.bucket(gcs_storage_bucket)\n",
        "\n",
        "  # Construct a client side representation of a blob.\n",
        "  # Note `Bucket.blob` differs from `Bucket.get_blob` as it doesn't retrieve\n",
        "  # any content from Google Cloud Storage. As we don't need additional data,\n",
        "  # using `Bucket.blob` is preferred here.\n",
        "  blob = bucket.blob(object_name)\n",
        "  blob.download_to_filename(destination_file_name)\n",
        "\n",
        "  print(\n",
        "      \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
        "          object_name, gcs_storage_bucket, destination_file_name\n",
        "      )\n",
        "  )"
      ],
      "metadata": {
        "id": "N7FijsCezJQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: python to delete a file even if it does not exist\n",
        "\n",
        "def delete_file(filename):\n",
        "  try:\n",
        "    os.remove(filename)\n",
        "    print(f\"File '{filename}' deleted successfully.\")\n",
        "  except FileNotFoundError:\n",
        "    print(f\"File '{filename}' not found.\")"
      ],
      "metadata": {
        "id": "lmqQixNHZfRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PrettyPrintJson(json_string):\n",
        "  json_object = json.loads(json_string)\n",
        "  json_formatted_str = json.dumps(json_object, indent=2)\n",
        "  print(json_formatted_str)\n",
        "  return json.dumps(json_object)"
      ],
      "metadata": {
        "id": "Tq3HEggwhEL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Brainstorming with Gemini"
      ],
      "metadata": {
        "id": "yGabI7sqh4Av"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sample Prompt"
      ],
      "metadata": {
        "id": "07IHMjfAkD1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "Write a 1-minute video script for Chocolate A.I., a fictional eco-conscious coffee company in London, launching their new \"Mocha Magic\" drink. The script should be engaging for coffee lovers, highlight the sustainable practices of Chocolate A.I., and follow the ABCD framework for effective video ads (Attention, Branding, Connection, Direction).\n",
        "\n",
        "Target Audience: Coffee lovers in London\n",
        "Theme: Eco-friendly, sustainable coffee, introducing the \"Mocha Magic\"\n",
        "Length: 60 seconds (10 x 6-second segments)\n",
        "Style: Upbeat, modern, and visually appealing\n",
        "\n",
        "Output for each 6 second segment:\n",
        "Visuals:\n",
        "Audio: Voiceover:\n",
        "Prompt:\n",
        "ABCD Rules:\n",
        "\n",
        "Here are the ABCD rules:\n",
        "Feature detected: Quick Pacing:\n",
        "Feature detected: Quick Pacing (First 5 seconds):\n",
        "Quick Pacing (First 5 seconds):\n",
        "Dynamic Start: True\n",
        "Feature detected: Supers: False\n",
        "Feature detected: Supers with Audio:\n",
        "Feature detected: Brand Visuals:\n",
        "Feature detected: Brand Visuals (First 5 seconds):\n",
        "Brand Visuals (First 5 seconds):\n",
        "Feature detected: Brand Mention (Speech):\n",
        "Feature detected: Brand Mention (Speech) (First 5 seconds):\n",
        "Brand Mention (Speech):\n",
        "Brand Mention (Speech) (First 5 seconds):\n",
        "Feature detected: Product Visuals:\n",
        "Feature detected:\n",
        "Product Visuals (First 5 seconds):\n",
        "Product Visuals: True\n",
        "Product Visuals (First 5 seconds):\n",
        "Feature detected: Product Mention (Text):\n",
        "Feature detected: Product Mention (Text) (First 5 seconds):\n",
        "Product Mention (Text):\n",
        "Product Mention (Text) (First 5 seconds): False\n",
        "Feature detected: Product Mention (Speech):\n",
        "Feature detected: Product Mention (Speech) (First 5 seconds):\n",
        "Product Mention (Speech)\n",
        "Product Mention (Speech) (First 5 seconds): F\n",
        "Feature detected: Visible Face (First 5 seconds):\n",
        "Feature detected: Visible Face (Close Up): Visible Face (First 5 seconds):\n",
        "Visible Face (Close Up):\n",
        "Feature detected: Presence of People (First 5 seconds): True\n",
        "Presence of People:\n",
        "Presence of People (First 5 seconds):\n",
        "Audio Early (First 5 seconds):\n",
        "Overall Pacing:\n",
        "Call To Action (Speech):\n",
        "Call To Action (Text)\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "G40yo7CZh67v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Gemini Sample Response"
      ],
      "metadata": {
        "id": "MWdJ9eE1kGoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chocolate A.I. \"Mocha Magic\" Video Script (60 seconds)\n",
        "\n",
        "**Segment 1 (6 seconds)**\n",
        "\n",
        "**Visuals:**  Fast-paced montage of iconic London scenes: bustling streets, red buses, Tower Bridge, people enjoying coffee in cafes.\n",
        "**Audio:** Upbeat, trendy music bed starts.\n",
        "**Voiceover:** \"London, you're always on the go…\"\n",
        "**Prompt:**  Fast-paced, vibrant visuals to grab attention.\n",
        "**ABCD Rules:** Attention, Quick Pacing, Dynamic Start, Presence of People, Audio Early, Overall Pacing: Fast.\n",
        "\n",
        "**Segment 2 (6 seconds)**\n",
        "\n",
        "**Visuals:** Close-up of a Chocolate A.I. barista crafting a latte art design – a swirling bean transforming into a magic hat.\n",
        "**Audio:**  Music transitions to a smoother, jazzier vibe.\n",
        "**Voiceover:** \"But you deserve a coffee break that's truly… magical.\"\n",
        "**Prompt:**  Introduce the brand subtly through the latte art and smoother music.\n",
        "**ABCD Rules:** Branding, Brand Visuals, Product Visuals, Overall Pacing: Moderate.\n",
        "\n",
        "**Segment 3 (6 seconds)**\n",
        "\n",
        "**Visuals:** The barista places the finished \"Mocha Magic\" drink on the counter. Steam rises, revealing the name “Mocha Magic” stylishly written on the cup.\n",
        "**Audio:** A gentle \"whoosh\" sound effect as the steam reveals the name.\n",
        "**Voiceover:** \"Introducing... Mocha Magic.\"\n",
        "**Prompt:**  First clear product reveal, emphasizing the name visually and aurally.\n",
        "**ABCD Rules:**  Product Visuals, Product Mention (Speech), Overall Pacing: Moderate.\n",
        "\n",
        "**Segment 4 (6 seconds)**\n",
        "\n",
        "**Visuals:**  Close-up shots of the drink's ingredients: ethically sourced cocoa beans, creamy oat milk being poured, a sprinkle of cinnamon.\n",
        "**Audio:** Upbeat music returns, but with a lighter, more natural feel.\n",
        "**Voiceover:** \"Ethically sourced cocoa, creamy oat milk, and a sprinkle of magic.\"\n",
        "**Prompt:** Highlight the premium and sustainable ingredients.\n",
        "**ABCD Rules:**  Product Visuals, Connection (appeal to values), Overall Pacing: Moderate.\n",
        "\n",
        "**Segment 5 (6 seconds)**\n",
        "\n",
        "**Visuals:** People from diverse backgrounds enjoying Mocha Magic in different settings: a park, by the Thames, inside a cozy Chocolate A.I. cafe.\n",
        "**Audio:**  Music becomes more relaxed and joyful.\n",
        "**Voiceover:**  \"The perfect pick-me-up, guilt-free.\"\n",
        "**Prompt:** Show the drink being enjoyed by the target audience, emphasizing the feel-good factor.\n",
        "**ABCD Rules:** Connection (emotion, lifestyle), Presence of People, Overall Pacing: Moderate.\n",
        "\n",
        "**Segment 6 (6 seconds)**\n",
        "\n",
        "**Visuals:** Shots of Chocolate A.I.' sustainable practices: a bicycle courier delivering coffee, a barista composting coffee grounds, a close-up of a \"Fair Trade Certified\" label.\n",
        "**Audio:**  Uplifting music continues.\n",
        "**Voiceover:**  \"Chocolate A.I.: Good for you, good for the planet.\"\n",
        "**Prompt:**  Reinforce the brand's commitment to sustainability.\n",
        "**ABCD Rules:** Branding, Connection (values), Overall Pacing: Moderate.\n",
        "\n",
        "**Segment 7 (6 seconds)**\n",
        "\n",
        "**Visuals:** A map of London highlighting Chocolate A.I. locations. A hand reaches for a Mocha Magic drink through a cafe window.\n",
        "**Audio:**  Music transitions back to the upbeat, trendy vibe from the beginning.\n",
        "**Voiceover:** \"Find your Mocha Magic at a Chocolate A.I. near you.\"\n",
        "**Prompt:**  Clear call to action with location information.\n",
        "**ABCD Rules:**  Direction, Call to Action (Speech), Overall Pacing: Moderate.\n",
        "\n",
        "**Segment 8 (6 seconds)**\n",
        "\n",
        "**Visuals:** A close-up shot of a Chocolate A.I. cup with the Mocha Magic logo and the text \"Try one today!\" appearing below.\n",
        "**Audio:** Music fades out. A final, satisfying \"slurp\" sound effect.\n",
        "**Voiceover:** \"Chocolate A.I.. Coffee with a conscience.\"\n",
        "**Prompt:**  End with a strong brand message and another call to action.\n",
        "**ABCD Rules:** Branding, Product Visuals, Call to Action (Text), Overall Pacing: Slowing Down.\n",
        "\n",
        "**Segment 9 (6 seconds)**\n",
        "\n",
        "**Visuals:**  The Chocolate A.I. logo on a clean background with their website address below.\n",
        "**Audio:** Silence.\n",
        "**Prompt:**  Provide clear branding and website information for viewers to remember.\n",
        "**ABCD Rules:**  Branding, Direction, Overall Pacing: Slow.\n",
        "\n",
        "**Segment 10 (6 seconds)**\n",
        "\n",
        "**Visuals:**  Fade to black.\n",
        "**Audio:**  Silence.\n",
        "**Prompt:**  Clean and impactful ending.\n",
        "**ABCD Rules:**  Overall Pacing: Slow.\n"
      ],
      "metadata": {
        "id": "7yaxBI2GkHjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Call Gemini to create a storyline for our Marketing Campaign"
      ],
      "metadata": {
        "id": "6hACSKgfSlDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetMenuItems():\n",
        "  sql = f\"\"\"SELECT TO_JSON(STRUCT(menu_name, menu_description)) AS menu_item_json\n",
        "  FROM `chocolate_ai.menu`\"\"\"\n",
        "\n",
        "  result_df = RunQuery(sql)\n",
        "  result_str = \"\"\n",
        "\n",
        "  for index, row in result_df.iterrows():\n",
        "    result_str = result_str + row['menu_item_json'] + \",\"\n",
        "\n",
        "  return '[' + result_str + ']'"
      ],
      "metadata": {
        "id": "rxaixDB51xVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to tell the LLM how to write text-to-video prompts\n",
        "\n",
        "text_to_video_prompt_guide = \"\"\"\n",
        "Text-to-Video Prompt Writing Help:\n",
        "<text-to-video-prompt-guide>\n",
        "Here are some our best practices for text-to-video prompts:\n",
        "\n",
        "Detailed prompts = better videos:\n",
        "  - More details you add, the more control you’ll have over the video. A prompt should look like this:\n",
        "  - Example Prompt: \"Camera dollies to show a close up of a desperate man in a green trench coat is making a call on a rotary style wall-phone, green neon light, movie scene.\"\n",
        "    - Here is a break down of a text-to-video prompt:\n",
        "    - Camera dollies to show = Camera motion\n",
        "    - A close up of = Composition\n",
        "    - A desperate man in a green trench coat = Subject\n",
        "    - Is making a call = Action\n",
        "    - On a roary style wall-phone = Scene\n",
        "    - Green Neon light = Ambiance\n",
        "    - Movie Scene = Style\n",
        "\n",
        "Use the right keywords for better control:\n",
        "  - We’ve identified a list of some keywords that work well with Veo, use these in your human written prompts to get the desired camera motion or style.\n",
        "  - Subject: Who or what is the main focus of the shot e.g. happy woman in her 30s\n",
        "  - Scene: Where is the location of the shot (on a busy street, in space)\n",
        "  - Action: What is the subject doing (walking, running, turning head)\n",
        "  - Camera Motion: What the camera is doing e.g. POV shot, Aerial View, Tracking Drone view, Tracking Shot\n",
        "    - Example Camera Motion: \"Tracking drone view of a man driving a red convertible car in Palm Springs, 1970s, warm sunlight, long shadows\"\n",
        "    - Example Camera Motion: \"A POV shot from a vintage car driving in the rain, Canada at night, cinematic\"\n",
        "\n",
        "\n",
        "Styles:\n",
        "   - Overall aesthetic. Consider using specific film style keywords e.g. horror film, film noir or animated styles e.g. 3D cartoon style render\n",
        "  - Example Prompt: \"Over the shoulder of a young woman in a car, 1970s, film grain, horror film, cinematic he Film noir style, man and woman walk on the street, mystery, cinematic, black and white\"\n",
        "  - Example Prompt: \"A cute creatures with snow leopard-like fur is walking in winter forest, 3D cartoon style render. An architectural rendering of a white concrete apartment building with flowing organic shapes, seamlessly blending with lush greenery and futuristic elements.\"\n",
        "\n",
        "Composition:\n",
        "  - How the shot is framed. This is often relative to the subject e.g. wide shot, close-up, low angle\n",
        "  - Example Prompt: \"Extreme close-up of a an eye with city reflected in it. A wide shot of surfer walking on a beach with a surfboard, beautiful sunset, cinematic\"\n",
        "\n",
        "Ambiance & Emotions:\n",
        "  - How the color and light contribute to the scene (blue tones, night)\n",
        "  - Example Prompt: \"A close-up of a girl holding adorable golden retriever puppy in the park, sunlight Cinematic close-up shot of a sad woman riding a bus in the rain, cool blue tones, sad mood\"\n",
        "\n",
        "Cinematic effects:\n",
        "  - e.g. double exposure, projected, glitch camera effect\n",
        "  - Example Prompt: \"A double exposure of silhouetted profile of a woman walking and lake, walking in a forest Close-up shot of a model with blue light with geometric shapes projected on her face\"\n",
        "  - Example Prompt: \"Silhouette of a man walking in collage of cityscapes Glitch camera effect, close up of woman’s face speaking, neon colors\"\n",
        "</text-to-video-prompt-guide>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RivD3xaHL1Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write me the json in  OpenAPI 3.0 schema object for the below object.\n",
        "# Make all fields required.\n",
        "#  {\n",
        "#    \"marketing-campaign-overview\" : :\"text\",\n",
        "#    \"segments\" : [\n",
        "#                 {\n",
        "#                   \"segment-number\" : 0,\n",
        "#                   \"visuals\" : \"\",\n",
        "#                   \"voiceover\" : \"\",\n",
        "#                   \"video-prompt\" : \"\",\n",
        "#                   \"ABCD-rules\" : [\"\",\"\"],\n",
        "#                 }\n",
        "#                 ]\n",
        "#  }\n",
        "response_schema = {\n",
        "  \"type\": \"object\",\n",
        "  \"required\": [\n",
        "    \"marketing-campaign-overview\",\n",
        "    \"segments\"\n",
        "  ],\n",
        "  \"properties\": {\n",
        "    \"marketing-campaign-overview\": {\n",
        "      \"type\": \"string\"\n",
        "    },\n",
        "    \"segments\": {\n",
        "      \"type\": \"array\",\n",
        "      \"items\": {\n",
        "        \"type\": \"object\",\n",
        "        \"required\": [\n",
        "          \"segement-number\"\n",
        "          \"visuals\",\n",
        "          \"audio\",\n",
        "          \"voiceover\",\n",
        "          \"ABCD-rules\"\n",
        "        ],\n",
        "        \"properties\": {\n",
        "          \"segement-number\": {\n",
        "            \"type\": \"integer\",\n",
        "            \"format\": \"int64\"\n",
        "          },\n",
        "          \"visuals\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"voiceover\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"video-prompt\": {\n",
        "            \"type\": \"string\"\n",
        "          },\n",
        "          \"ABCD-rules\": {\n",
        "            \"type\": \"array\",\n",
        "            \"items\": {\n",
        "              \"type\": \"string\"\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "menu_items = GetMenuItems()\n",
        "\n",
        "gemini_ad_prompt = f\"\"\"Write a {video_length_in_seconds}-second video script that showcases the artistry of chocolatiers crafting exquisite desserts.\n",
        "This is a new company Chocolate AI who wants to build their brand awarness.\n",
        "The company is based in Paris, France.\n",
        "The video will be generated by GenAI and needs to be magicical and spark the imagination of the viewers.\n",
        "The video should show AI in action like data points swirling, algorithms working, personalized recommendations being generated.\n",
        "Feature a range of signature offerings from the below menu.\n",
        "Encourage unconventional ideas and fresh perspectives and inspires unique variations when viewing the video.\n",
        "The video should be shot inside the cholcolate shop or show the street outside the shop.\n",
        "\n",
        "Output Fields:\n",
        "- Segment Number: The number of the segment.  There should be 10 segments.\n",
        "- Visuals: A brief description of the visual elements for the segment.\n",
        "- Voiceover: A concise voiceover script for the segment.  This should be 6 to 10 words.\n",
        "- Video Prompt:\n",
        "  - Read the below \"Text-to-Video Prompt Writing Help\" to learn more about how to create good text-to-video prompts.\n",
        "  - A detailed prompt for generating the video using text-to-video technology.\n",
        "  - Focus on text-to-video that shows the chocolates being made since text-to-video can generate that well.\n",
        "  - Keep the prompt focused on a single thought and keep it simple.\n",
        "  - Do not create a prompt that is too abstract, stick to things GenAI can easily understand.\n",
        "  - Avoid using \"text overlays\" in the video prompt.\n",
        "  - Focus on chocolates and coffee drinks in the menu\n",
        "  - Feel free to use robots making the chocolates and coffee drinks, we want some text in some of the segments.\n",
        "- ABCD Rules: The relevant ABCD rules that should be applied to the segment.\n",
        "- Note: The ABCD rules are a specific set of guidelines that you may or may not be using.\n",
        "\n",
        "{text_to_video_prompt_guide}\n",
        "\n",
        "<ai-sweets-menu>\n",
        "{menu_items}\n",
        "</ai-sweets-menu>\n",
        "\n",
        "<ABCD-Rules>\n",
        "Quick Pacing\n",
        "Quick Pacing (First 5 seconds)\n",
        "Dynamic Start\n",
        "Supers\n",
        "Supers with Audio\n",
        "Brand Visuals\n",
        "Brand Visuals (First 5 seconds)\n",
        "Brand Mention (Speech)\n",
        "Brand Mention (Speech) (First 5 seconds)\n",
        "Product Visuals\n",
        "Product Visuals (First 5 seconds)\n",
        "Product Mention (Text)\n",
        "Product Mention (Text) (First 5 seconds)\n",
        "Product Mention (Speech)\n",
        "Product Mention (Speech) (First 5 seconds)\n",
        "Visible Face (First 5 seconds)\n",
        "Visible Face (Close Up)\n",
        "Presence of People\n",
        "Presence of People (First 5 seconds)\n",
        "Overall Pacing\n",
        "Audio Speech Early\n",
        "Call To Action (Text)\n",
        "Call To Action (Speech)\n",
        "</ABCD-Rules>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "multimodal_prompt_list = [\n",
        "    { \"text\": gemini_ad_prompt },\n",
        "  #  { \"fileData\": {  \"mimeType\": \"application/pdf\", \"fileUri\": f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/text-to-video-{formatted_date}/VeoPromptWritingGuide.pdf\" } }\n",
        "  ]\n",
        "\n",
        "print(gemini_ad_prompt)\n",
        "llm_result = GeminiLLM_Multimodal(multimodal_prompt_list, response_schema=response_schema)\n",
        "gemini_ad_results_dict = json.loads(llm_result)\n",
        "orginal_ad_results_dict = gemini_ad_results_dict # in case we swap it for a pre-canned one\n",
        "print()\n",
        "print(gemini_ad_results_dict)"
      ],
      "metadata": {
        "id": "Nn7mYNVy5EMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PrettyPrintJson(json.dumps(gemini_ad_results_dict))"
      ],
      "metadata": {
        "id": "gAqNEyfdVohu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create local working directories"
      ],
      "metadata": {
        "id": "e0xMMVppTzJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to download the videos from GCS and a directory to combine the text to speech and videos\n",
        "directory_text_to_video = f\"text-to-video-{formatted_date}\"\n",
        "directory_text_to_speech = f\"text-to-speech-{formatted_date}\"\n",
        "directory_video_and_audio = f\"video-and-audio-{formatted_date}\"\n",
        "directory_full_video = f\"full-video-{formatted_date}\"\n",
        "\n",
        "os.makedirs(directory_text_to_video, exist_ok=True)\n",
        "directory_text_to_video_path = os.getcwd() + f\"/{directory_text_to_video}/\"\n",
        "print(f\"directory_text_to_video_path: {directory_text_to_video_path}\")\n",
        "\n",
        "os.makedirs(directory_text_to_speech, exist_ok=True)\n",
        "directory_text_to_speech_path = os.getcwd() + f\"/{directory_text_to_speech}/\"\n",
        "print(f\"directory_text_to_speech_path: {directory_text_to_speech_path}\")\n",
        "\n",
        "os.makedirs(directory_video_and_audio, exist_ok=True)\n",
        "directory_video_and_audio_path = os.getcwd() + f\"/{directory_video_and_audio}/\"\n",
        "print(f\"directory_video_and_audio_path: {directory_video_and_audio_path}\")\n",
        "\n",
        "os.makedirs(directory_full_video, exist_ok=True)\n",
        "directory_full_video_path = os.getcwd() + f\"/{directory_full_video}/\"\n",
        "print(f\"directory_full_video_path: {directory_full_video_path}\")\n",
        "\n",
        "full_video_filename = directory_full_video_path + \"full-video.mp4\"\n",
        "print(f\"full_video_filename: {full_video_filename}\")"
      ],
      "metadata": {
        "id": "o6q7b54ZT1iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Video Generation"
      ],
      "metadata": {
        "id": "6GTNHglPkDV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Precanned Video #1"
      ],
      "metadata": {
        "id": "cqatuWfYMHjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Precanned Video #1\n",
        "precanned_01_mocha_magic_ad_script = {\n",
        "    \"marketing-campaign-overview\": 'This 60-second video ad introduces London coffee lovers to \"Mocha Magic,\" a new drink by Chocolate A.I., highlighting the company\\'s commitment to sustainability and ethical sourcing.',\n",
        "    \"segments\": [\n",
        "        {\n",
        "            \"ABCD-rules\": [\n",
        "                \"Quick Pacing\",\n",
        "                \"Quick Pacing (First 5 seconds)\",\n",
        "                \"Dynamic Start\",\n",
        "                \"Supers with Audio\",\n",
        "                \"Brand Visuals\",\n",
        "                \"Brand Visuals (First 5 seconds)\",\n",
        "            ],\n",
        "            \"voiceover\": \"Ever wished for a coffee that's truly... magical?\",\n",
        "            \"segement-number\": 1,\n",
        "            \"video-prompt\": \"Close-up shot of a single coffee bean, rotating slowly against a black background.\",\n",
        "            \"visuals\": 'Close-up shot of a single coffee bean, rotating slowly against a black background.',\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\n",
        "                \"Quick Pacing\",\n",
        "                \"Product Visuals\",\n",
        "                \"Product Visuals (First 5 seconds)\",\n",
        "                \"Product Mention (Text)\",\n",
        "                \"Product Mention (Text) (First 5 seconds)\",\n",
        "            ],\n",
        "            \"voiceover\": \"Introducing Chocolate A.I. Mocha Magic. Crafted with care, from bean to cup.\",\n",
        "            \"segement-number\": 2,\n",
        "            \"video-prompt\": \"Aerial drone shot of vast, vibrant green coffee fields bathed in sunlight.\",\n",
        "            \"visuals\": 'Aerial drone shot of vast, vibrant green coffee fields bathed in sunlight.',\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\n",
        "                \"Product Visuals\",\n",
        "                \"Visible Face (First 5 seconds)\",\n",
        "                \"Presence of People\",\n",
        "                \"Presence of People (First 5 seconds)\",\n",
        "            ],\n",
        "            \"voiceover\": \"Expertly selected beans, bursting with rich, chocolatey notes.\",\n",
        "            \"segement-number\": 3,\n",
        "            \"video-prompt\": 'Close-up of weathered hands gently picking ripe coffee cherries.',\n",
        "            \"visuals\": 'Close-up of weathered hands gently picking ripe coffee cherries.',\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\n",
        "                \"Visible Face (Close Up)\",\n",
        "                \"Presence of People\",\n",
        "                \"Overall Pacing\",\n",
        "                \"Audio Speech Early\",\n",
        "            ],\n",
        "            \"voiceover\": \"Naturally dried under the sun, for a smooth, decadent flavor.\",\n",
        "            \"segement-number\": 4,\n",
        "            \"video-prompt\": 'Time-lapse of coffee beans drying naturally on raised beds under the sun.',\n",
        "            \"visuals\": 'Time-lapse of coffee beans drying naturally on raised beds under the sun.',\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\n",
        "                \"Brand Mention (Speech)\",\n",
        "                \"Brand Mention (Speech) (First 5 seconds)\",\n",
        "                \"Product Visuals\",\n",
        "            ],\n",
        "            \"voiceover\": \"Roasted to perfection, unlocking the magic within.\",\n",
        "            \"segement-number\": 5,\n",
        "            \"video-prompt\": \"Artisan roaster carefully monitoring coffee beans as they roast in a traditional drum roaster.\",\n",
        "            \"visuals\": \"Artisan roaster carefully monitoring coffee beans as they roast in a traditional drum roaster.\",\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\"Product Mention (Speech)\"],\n",
        "            \"voiceover\": \"Find Mocha Magic at a Chocolate A.I. truck near you!\",\n",
        "            \"segement-number\": 6,\n",
        "            \"video-prompt\": \"A sleek, modern Chocolate A.I. mobile coffee truck pulls up to a bustling London location, like Covent Garden.\",\n",
        "            \"visuals\": \"A sleek, modern Chocolate A.I. mobile coffee truck pulls up to a bustling London location, like Covent Garden.\",\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\"Product Mention (Speech)\"],\n",
        "            \"voiceover\": \"Indulge in layers of velvety chocolate, rich espresso, and a touch of sweetness.\",\n",
        "            \"segement-number\": 7,\n",
        "            \"video-prompt\": \"Barista expertly prepares a Mocha Magic latte, showcasing latte art - perhaps a swirling, magical design.\",\n",
        "            \"visuals\": \"Barista expertly prepares a Mocha Magic latte, showcasing latte art - perhaps a swirling, magical design.\",\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\"Product Mention (Speech)\"],\n",
        "            \"voiceover\": \"Mocha Magic - your new London obsession.\",\n",
        "            \"segement-number\": 8,\n",
        "            \"video-prompt\": 'Montage of people from diverse backgrounds enjoying Mocha Magic in different London settings: by the Thames, in a park, at a market.',\n",
        "            \"visuals\": 'Montage of people from diverse backgrounds enjoying Mocha Magic in different London settings: by the Thames, in a park, at a market.',\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\n",
        "                \"Product Mention (Speech)\",\n",
        "                \"Product Mention (Speech) (First 5 seconds)\",\n",
        "            ],\n",
        "            \"voiceover\": \"Experience the magic. Chocolate A.I.: Sustainably Delicious.\",\n",
        "            \"segement-number\": 9,\n",
        "            \"video-prompt\": 'Close-up of a Chocolate A.I. Mocha Magic latte with latte art, steam rising enticingly. Chocolate A.I. logo appears subtly on the cup.',\n",
        "            \"visuals\": 'Close-up of a Chocolate A.I. Mocha Magic latte with latte art, steam rising enticingly. Chocolate A.I. logo appears subtly on the cup.',\n",
        "        },\n",
        "        {\n",
        "            \"ABCD-rules\": [\"Call To Action (Text)\", \"Call To Action (Speech)\"],\n",
        "            \"voiceover\": \"Chocolate A.I.. Find Your Magic\",\n",
        "            \"segement-number\": 10,\n",
        "            \"video-prompt\": \"Start with a close-up shot of a steaming 'Mocha Magic' latte with the intricate latte art. As the steam rises and swirls, transition to a shot of a bustling London street scene with people walking by (Covent Garden or a similar vibrant location). Briefly overlay text near the end: 'Sustainably Delicious'.\",\n",
        "            \"visuals\": \"Start with a close-up shot of a steaming 'Mocha Magic' latte with the intricate latte art. As the steam rises and swirls, transition to a shot of a bustling London street scene with people walking by (Covent Garden or a similar vibrant location). Briefly overlay text near the end: 'Sustainably Delicious'.\",\n",
        "        },\n",
        "    ],\n",
        "}\n"
      ],
      "metadata": {
        "id": "iz2ZCClFLYiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### generateVideo"
      ],
      "metadata": {
        "id": "5XxZTZVCOEjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: This has NOT BEEN tested, it requires allow listing\n",
        "\n",
        "def generateVideo(prompt, full_output_gcs_path_and_filename):\n",
        "  return True\n",
        "\n",
        "  \"\"\"Calls Veo to create the video and waits for the output (which can be several minutes)\"\"\"\n",
        "\n",
        "  # Call Veo and wait for the files to be generated\n",
        "  # https://cloud.google.com/vertex-ai/generative-ai/docs/image/text-to-live-images#rest\n",
        "\n",
        "  #curl -X POST \\\n",
        "  #    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  #    -H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "  #    \"https://us-central1-aiplatform.googleapis.com/v1/projects/data-analytics-preview/locations/us-central1/publishers/google/models/veo-001-preview:predictLongRunning\" \\\n",
        "  #    -d ''\n",
        "\n",
        "  #curl -X GET \\\n",
        "  #    -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
        "  #    -H \"Content-Type: application/json; charset=utf-8\" \\\n",
        "  #    \"https://us-central1-aiplatform.googleapis.com/v1/projects/data-analytics-preview/locations/us-central1/publishers/google/models/veo-001-preview:fetchPredictOperation\" \\\n",
        "  #    -d '{ \"operationName\": \"OPERATION_NAME\" }'\n",
        "\n",
        "  model = \"veo-001-preview\"\n",
        "  url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{region}/publishers/google/models/{model}:predictLongRunning\"\n",
        "\n",
        "  request_body = {\n",
        "      \"instances\": [\n",
        "          {\n",
        "              \"prompt\": prompt\n",
        "          }\n",
        "        ],\n",
        "      \"parameters\": {\n",
        "          \"storageUri\": full_output_gcs_path_and_filename,\n",
        "          \"aspectRatio\":\"16:9\"\n",
        "          }\n",
        "      }\n",
        "\n",
        "  \"\"\"\n",
        "  ???\n",
        "  \"\"\"\n",
        "\n",
        "  json_result = restAPIHelper(url, \"POST\", request_body)\n",
        "  operation_name = json_result[\"operation_name\"]\n",
        "\n",
        "  url = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{project_id}/locations/{region}/publishers/google/models/{model}:fetchPredictOperation\"\n",
        "\n",
        "  request_body = {\n",
        "      \"operationName\": operation_name\n",
        "      }\n",
        "\n",
        "  json_result = restAPIHelper(url, \"POST\", request_body)\n",
        "  status = json_result[\"status\"]\n",
        "\n",
        "  while status == \"RUNNING\":\n",
        "    time.sleep(10)\n",
        "    json_result = restAPIHelper(url, \"POST\", request_body)\n",
        "    status = json_result[\"status\"]\n",
        "\n",
        "  return True"
      ],
      "metadata": {
        "id": "dkyDpT8SOE2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create the Videos (using Veo)"
      ],
      "metadata": {
        "id": "4vwwZIC-MLPJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9c_G_2J6FZD"
      },
      "outputs": [],
      "source": [
        "# Veo\n",
        "\n",
        "# Output of video files\n",
        "veo_file_name = \"mocha-magic-part-video-only-SEGMENT.mp4\"\n",
        "veo_gcs_path = f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/veo-output/mocha-magic-ad-{formatted_date}/\"\n",
        "veo_bucket = storage_account\n",
        "\n",
        "# If you want to use the pre-generate video this will use data from the public storage account\n",
        "if use_precanned_demo:\n",
        "  if which_precanned_demo == \"precanned_01_mocha_magic_ad_script\":\n",
        "    # Make the precanned_01_mocha_magic_ad_script the gemini_ad_results_dict\n",
        "    gemini_ad_results_dict = precanned_01_mocha_magic_ad_script\n",
        "    veo_gcs_path = f\"gs://{public_storage_storage_account}/chocolate-ai/v2/DB-GMA-Campaign-Assets-Video-Text2Video/Mocha-Magic/\"\n",
        "    veo_bucket = public_storage_storage_account\n",
        "\n",
        "# This will take ~3-4 minutes per video (so this can take over an half an hour)\n",
        "for item in gemini_ad_results_dict['segments']:\n",
        "  video_prompt = item['video-prompt']\n",
        "  i = item['segement-number']\n",
        "  formatted_i = i\n",
        "  if i < 10:\n",
        "    formatted_i = f\"0{i}\"\n",
        "\n",
        "  filename = veo_file_name.replace(\"SEGMENT\", str(formatted_i))\n",
        "  full_output_gcs_path_and_filename = veo_gcs_path + filename\n",
        "\n",
        "  print(f\"Generating {i}: {video_prompt} [{full_output_gcs_path_and_filename}]\")\n",
        "\n",
        "  # Generate video (if precanned then skip to save time)\n",
        "  if use_precanned_demo == False:\n",
        "    generateVideo(video_prompt, full_output_gcs_path_and_filename)\n",
        "\n",
        "  item[\"video-veo-gcs-filename\"] = full_output_gcs_path_and_filename\n",
        "  item[\"video-gcs-copy-filename\"] = f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/\" + filename\n",
        "  item[\"video-local-filename\"] = directory_text_to_video_path + filename\n",
        "\n",
        "  # Download completed video\n",
        "  download_from_gcs(item[\"video-local-filename\"], veo_bucket, full_output_gcs_path_and_filename.replace(f\"gs://{veo_bucket}/\",\"\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text to Speech Generation"
      ],
      "metadata": {
        "id": "nOWzEh-WkGfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out a list of language code, select one you want\n",
        "response_text = TextToSpeechLanguageList(\"en-gb\")\n",
        "response_json = json.loads(response_text)\n",
        "print (response_json)\n",
        "# print(PrettyPrintJson(response_text))\n",
        "\n",
        "language_code = \"en-gb\"\n",
        "language_code_name = \"en-GB-Neural2-A\"\n",
        "ssml_gender = \"FEMALE\""
      ],
      "metadata": {
        "id": "tcMqiiQqhUE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the text-to-speech for each segment\n",
        "\n",
        "# Output of video files\n",
        "audio_file_name = \"mocha-magic-part-audio-only-SEGMENT.mp3\"\n",
        "\n",
        "for item in gemini_ad_results_dict['segments']:\n",
        "  voiceover_prompt = item['voiceover']\n",
        "  i = item['segement-number']\n",
        "  formatted_i = i\n",
        "  if i < 10:\n",
        "    formatted_i = f\"0{i}\"\n",
        "\n",
        "  filename = audio_file_name.replace(\"SEGMENT\", str(formatted_i))\n",
        "  item[\"audio-local-filename\"] = directory_text_to_speech_path + filename\n",
        "  item[\"audio-gcs-copy-filename\"] = f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/\" + filename\n",
        "\n",
        "  print(f\"Generating {i}: {voiceover_prompt}\")\n",
        "\n",
        "  # Text-to-Speech\n",
        "  TextToSpeech(item[\"audio-local-filename\"], voiceover_prompt, language_code, language_code_name, ssml_gender, .9)\n",
        "  display(Audio(item[\"audio-local-filename\"], autoplay=True,rate=16000))\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "HbGpOSnsqEbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Speech and Videos"
      ],
      "metadata": {
        "id": "94init3ix9kE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the text-to-speech with the text-to-video\n",
        "\n",
        "# Output of video files\n",
        "video_and_audio_file_name = \"mocha-magic-part-audio-and-video-SEGMENT.mp4\"\n",
        "\n",
        "for item in gemini_ad_results_dict['segments']:\n",
        "  i = item['segement-number']\n",
        "  formatted_i = i\n",
        "  if i < 10:\n",
        "    formatted_i = f\"0{i}\"\n",
        "\n",
        "  filename = video_and_audio_file_name.replace(\"SEGMENT\", str(formatted_i))\n",
        "  item[\"combined-audio-and-video-local-filename\"] = directory_video_and_audio_path + filename\n",
        "  item[\"combined-audio-and-video-gcs-copy-filename\"] = f\"gs://{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/\" + filename\n",
        "\n",
        "  print(f\"Merging Segment {i}\")\n",
        "\n",
        "  # Text-to-Speech\n",
        "  MergeVideoAndAudio(item[\"video-local-filename\"], item[\"audio-local-filename\"], item[\"combined-audio-and-video-local-filename\"])"
      ],
      "metadata": {
        "id": "a38ZuOz1cer1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first merged file\n",
        "part_01_video_with_audio_mp4 = open(gemini_ad_results_dict['segments'][0][\"combined-audio-and-video-local-filename\"], 'rb').read()\n",
        "part_01_video_with_audio_mp4_url = \"data:video/mp4;base64,\" + base64.b64encode(part_01_video_with_audio_mp4).decode()"
      ],
      "metadata": {
        "id": "MWPygOjFKITJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the video\n",
        "# 16:9 aspect ratio\n",
        "HTML(f\"\"\"\n",
        "<video width=600 height=337 controls>\n",
        "      <source src=\"{part_01_video_with_audio_mp4_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "svGgFRm6KLT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the second merged file\n",
        "part_02_video_with_audio_mp4 = open(gemini_ad_results_dict['segments'][1][\"combined-audio-and-video-local-filename\"], 'rb').read()\n",
        "part_02_video_with_audio_mp4_url = \"data:video/mp4;base64,\" + base64.b64encode(part_02_video_with_audio_mp4).decode()"
      ],
      "metadata": {
        "id": "5l-Hqj_fPZBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Play the video\n",
        "# 16:9 aspect ratio\n",
        "HTML(f\"\"\"\n",
        "<video width=600 height=337 controls>\n",
        "      <source src=\"{part_02_video_with_audio_mp4_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "9kv-Uj0QPboG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge the videos into one video\n"
      ],
      "metadata": {
        "id": "QVsdBsl_Kjs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Warning: This does not currently produce a well edited video.**\n",
        "- The code works, but a final version was created using a video editting software."
      ],
      "metadata": {
        "id": "yEeUwEDLjgic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the videos (the file names are when sorted match the placement of each video in the overall video)\n",
        "\n",
        "print(\"Merging videos\")\n",
        "print(f\"directory_video_and_audio_path: {directory_video_and_audio_path}\")\n",
        "print(f\"full_video_filename: {full_video_filename}\")\n",
        "\n",
        "merge_videos_sorted(directory_video_and_audio_path, full_video_filename)"
      ],
      "metadata": {
        "id": "02ubD5duJGIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: python to play a mp4 in a jupyter notebook\n",
        "mocha_magic_ad_full_video_mp4 = open(full_video_filename, 'rb').read()\n",
        "mocha_magic_ad_full_video_url = \"data:video/mp4;base64,\" + base64.b64encode(mocha_magic_ad_full_video_mp4).decode()"
      ],
      "metadata": {
        "id": "Wgq5iz30CfwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16:9 aspect ratio\n",
        "HTML(f\"\"\"\n",
        "<p>Combined video using moviepy which needs some fine tuning</p>\n",
        "<video width=600 height=337 controls>\n",
        "      <source src=\"{mocha_magic_ad_full_video_url}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "zOf7J4OaDmSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"To see the Mocha Magic Video which was edited using video editing software.\")\n",
        "print(\"Open this to see the one edited manually: https://storage.googleapis.com/data-analytics-golden-demo/chocolate-ai/v2/DB-GMA-Campaign-Assets-Video-Text2Video/Mocha-Magic/mocha-magic-full-ad.mp4\")"
      ],
      "metadata": {
        "id": "n2swiEwHsfOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy Artifacts to Storage"
      ],
      "metadata": {
        "id": "A7_JWTrCaQ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload videos, audios, combined audio-video to storaege\n",
        "for item in gemini_ad_results_dict['segments']:\n",
        "  #print(f\"Copying {item['video-local-filename']} to {item['video-gcs-copy-filename']}\")\n",
        "  #print(f\"Copying {item['audio-local-filename']} to {item['audio-gcs-copy-filename']}\")\n",
        "  #print(f\"Copying {item['combined-audio-and-video-local-filename']} to {item['combined-audio-and-video-gcs-copy-filename']}\")\n",
        "  copy_file_to_gcs(item[\"video-local-filename\"], storage_account, item[\"video-gcs-copy-filename\"].replace(f\"gs://{storage_account}/\",\"\"))\n",
        "  copy_file_to_gcs(item[\"audio-local-filename\"], storage_account, item[\"audio-gcs-copy-filename\"].replace(f\"gs://{storage_account}/\",\"\"))\n",
        "  copy_file_to_gcs(item[\"combined-audio-and-video-local-filename\"], storage_account, item[\"combined-audio-and-video-gcs-copy-filename\"].replace(f\"gs://{storage_account}/\",\"\"))\n",
        "\n",
        "\n",
        "# Final combined output video\n",
        "copy_file_to_gcs(item[\"combined-audio-and-video-local-filename\"], storage_account, f\"chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/full-video.mp4\")\n",
        "\n",
        "# Save the prompt so we know how we got this data\n",
        "with open(\"gemini_ad_prompt.txt\", \"w\") as f:\n",
        "  f.write(gemini_ad_prompt)\n",
        "copy_file_to_gcs(\"gemini_ad_prompt.txt\", storage_account, f\"chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/gemini_ad_prompt.txt\")\n",
        "delete_file(\"gemini_ad_prompt.txt\")\n",
        "\n",
        "# Save the output of the prompt\n",
        "with open(\"gemini_ad_prompt_results.txt\", \"w\") as f:\n",
        "  f.write(PrettyPrintJson(json.dumps(orginal_ad_results_dict)))\n",
        "copy_file_to_gcs(\"gemini_ad_prompt_results.txt\", storage_account, f\"chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/gemini_ad_prompt_results.txt\")\n",
        "delete_file(\"gemini_ad_prompt_results.txt\")"
      ],
      "metadata": {
        "id": "NQMfPlDXaTRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To view the bucket\n",
        "print(f\"https://console.cloud.google.com/storage/browser/{storage_account}/chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}\")"
      ],
      "metadata": {
        "id": "yaumbdcDpvWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Option: Combine video only (no audio)"
      ],
      "metadata": {
        "id": "GmUdxl0opKNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is used for the DB-GMA-Campaign-Assets-Video-Create-Shorts.ipy Notebook\n",
        "merge_videos_sorted(directory_text_to_video_path, \"mocha-magic-video-only-combined.mp4\")\n",
        "copy_file_to_gcs(f\"{directory_text_to_video_path}mocha-magic-video-only-combined.mp4\", storage_account, f\"chocolate-ai/DB-GMA-Campaign-Assets-Video-Text2Video/mocha-magic-ad-{formatted_date}/mocha-magic-video-only-combined.mp4\")\n",
        "delete_file(f\"{directory_text_to_video_path}mocha-magic-video-only-combined.mp4\")"
      ],
      "metadata": {
        "id": "LxmH3nXSoy0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42IxhtRRrvR-"
      },
      "source": [
        "### Clean Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lF2Z7skFbvf"
      },
      "outputs": [],
      "source": [
        "user_input = input(\"Do you want to the files on this notebook machine (Y/n)?\")\n",
        "if user_input == \"Y\":\n",
        "  import shutil\n",
        "  print(f\"Removing directory: {directory_text_to_video_path}\")\n",
        "  shutil.rmtree(directory_text_to_video_path)\n",
        "\n",
        "  print(f\"Removing directory: {directory_text_to_speech_path}\")\n",
        "  shutil.rmtree(directory_text_to_speech_path)\n",
        "\n",
        "  print(f\"Removing directory: {directory_video_and_audio_path}\")\n",
        "  shutil.rmtree(directory_video_and_audio_path)\n",
        "\n",
        "  print(f\"Removing directory: {directory_full_video_path}\")\n",
        "  shutil.rmtree(directory_full_video_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQ2BPisXDA0"
      },
      "source": [
        "### Reference Links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRQZxRKA6FZE"
      },
      "source": [
        "- [Google.com](https://www.google.com)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HMsUvoF4BP7Y",
        "m65vp54BUFRi",
        "UmyL-Rg4Dr_f",
        "sZ6m_wGrK0YG",
        "JbOjdSP1kN9T",
        "Hh6lubX6VTHv",
        "wySHopHNei3E",
        "IT_AtoA3gV4q",
        "CWYQfM8BK5Sn",
        "bNKaaW5ohCpd",
        "yGabI7sqh4Av",
        "07IHMjfAkD1F",
        "MWdJ9eE1kGoU",
        "6hACSKgfSlDK",
        "e0xMMVppTzJ3",
        "cqatuWfYMHjd",
        "94init3ix9kE",
        "42IxhtRRrvR-",
        "ASQ2BPisXDA0"
      ],
      "name": "DB-GMA-Campaign-Assets-Video-Text2Video.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}